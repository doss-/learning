# [Gianluca Abezzano] DevOps never sleeps. What we learned from influxDB v1 to v2

Docker is pretty layered system, which is split even more recently after ContainerD is moved into OpenSource by Docker development team.

The layers if Docker infrastructure are:

1. CLI
> command line interface for accessing Docker daemon  
2. REST
> restfull interface for accessing daemon. TODO: check whether CLI also uses it
3. dockerd
> docker service that accepts CLI and REST  calls and translates them further tocontainerd service(daemon)  
4. containerd
> service that is moved into separate project. main purpose is to made this _Core_ service to be fully crossplatform. 
containerd daemon exposes its API that is  used by dockerd and others parties interested in communication witn containerd in order to use services it provides.
It is currently used everywhere where containers and docker are  used - AWS, Azure and all the cloud providers that adopted docker as engine for containerization. 
Also this is the core that runs on multiple OS such as: Linux, MacOS, Windows etc.  
5. RunC
> __TODO: write RunC description, and probably add more layers..__

__TODO: which of above uses Linux Socket\TCP Socket in order of communication with outer world.__

## Jenkins and k8s

Main point in usage of docker infrastructure by '3rd parties' is in acquiring access to docker socket.  
It could be illustrated by starting docker container with docker(sub) running inside it.  
Sub docker could manipulate parent docker if it has access to parent docker's socker, for instance by mounting socket file to sub docker's container:  

    TODO: write full command below.
    docker run -v /run/docker.sock:/run/docker.sock ....

in this example docker socket is passed from Host system into the container so docker running in the container could manipulate Host's one.

This is  how Jenkins plugin and k8s work.


## Tracing and effective logs monitoring

In order to trace different important events out of all the system information, unimportant warnings and errors information need to be correctly logged, aggregated and filtered.  
Metrics need to be used and calculated, and tracking of events throught different logs need to be applied to that. 

After all the logs are gathered, together with metrics and tracking applied to it, some particular thing could be Traced.

Metrics alone is just like slap to the face, it is sudden and only  has shock effect.

Logs in raw view are useless, the sence comes after aggregation and ability to filter it.

Tools:

- ELK(B)
- Prometheus(google)
- Jaeger

### State of the system.

Monitoring of the system could be done by monitoring its State:

- Hardware charasteritsitcs like CPU usage
- processes rununing and resource usage
- I\O activities 
- etc

But just snapshot is usually not enough.   
Like 'ps -lte' - it could return actual and correct info but it will not gave any meaningful info in order which process works ineffectively or wrong.  
For more efficient monitoring 'top' program will give much more info about processes and how they are utilizing system's resources.  
But this gives realtime results and requres constant attention, it order to find which process does what.  
So for effective monitor we need a tool that will save changes into history and ability to filter and even visualize the history.


But w/o any context even atual, filtered and visualized info makes no sence:

> __Normal State.__

When everything in the system runs OK, and everybody is satisfied we could call it the Normal State of the system.  
This state need to be saved with all the metrics calculated and attached, to be used later when need to determine how system works at given point of time.

> __Current State__

At any point of time we could apply all the filters to logs, calculate metrics and visualize statistics (even of some time period). This will give us the Current State.  
Comparing this _Current State_ with a 'golden standard' like _Normal State_ will give the answer to the main question:  
 _Whether everything is fine with our system Now?_


## Design applications correctly in order to monitor them later

In order to monitor system state effectively we need the info in first place.  
Info is the logs generated by apps which state we want to monitor.  

When Application is developed logs generation should be keep in mind. In ideal way app should has API to access logging functionality from outside by other systems: 

    [App [[Logs func + stuff ] API for logs access\creation]]

in that way some logs\events storage facility could use API to ask app for some particular logs an particular point of time.

### Code Instrumentation (hello Bullseye)

Existing code  also could be instrumented (i.e. during compilation)

Later on during runtime this added parts will fire and write logs\events somewhere ( i.e. into some stream). Also this added part could provide API access for other tools.  

Tools:

- bullseye
- OpenCensus(google\open source)

# [Philipp Krenn - Elastic] Hands-On ModSecurity and Logging

Basically this talk is about security breaches that could be logged and monitored uneffectively, thus alerting user too late and with lack of general information.  
Tool that is demonstrated in order to prevent both breaches and bad monitoring is ModSecurity

### Security issues

There could be gaps in app with security

Gaps could be covered outside the app with tools, that filter out traffic analizing its inner parts, like requests (i.e. request having 'update' sql directive will be filtered out in some case, and 'delete' almost everytime)

Some traffic fould be sniffed by the ModSecurity, and it will make a decision of what to do , whether block traffic completely (nevertheless notifying the logs 
) or just log info\warning\error.  

So in case ModS decided that traffic package has some malwarish things this request to the web server could be blocked preventing anything from happening and end user will get 503 error or something similar to it

### Logging an monitoryng issues

The app itself could writte logs, the instrumented app could write logs, and even apps running atof of main app could add logging

Logs are generated by ModSecutiry, then are gathered by  File Beat and fed into Logstash, which applies filters to match particular fields of the log to be filtered by or displayed in Kibana.  

Basically after ModSecurity is turned on and set up, it generates logs which could be viewed in ELK, containing all the info from where package came from, when, what it had, and in general full statistics could be gathered to understand whole picture.

> __Logs Enreachment__

Like taking IP from the logs and adding where it is from (country) to add meaning and context fo the logged info, w/o which it is pretty useless.  

### Other

Also the guy demonstrated the tool(probably his own, w/o sources or place to download) which is basically a python script, that receives the web address or particular page and runs various security checks like for injections and stuff like this.

# [Nikita Procenko - Netflix] Infrastructure-as-code: bringing the gap between Devs and Ops


