==========TODO:
create bash script that will export variables to:
1. current session
2. user .bashrc file so it will be available in other sessions
3. system-wide

check distribution and update according files for
1. user-wide
2. system-wide 

do the same for Bash Aliases


Save this script into this repo

===
identify myself on git
==========todo

Contents
===General
===Env Vars / Environment variables:
===User\Groups Management
=====User\Groups Management General info
=====Manipulate Users And Groups
=====Super User
===Processes and Services Management
===Package management
=====Debian\Ubuntu
=======Uninstallation
=======Repository setup
=======List all installed packages:
=====RedHat RHEL\Centos
=======Manage repositories
=======Uninstallation
=======List all installed packages:
===File Permissions / Ownership
===IPTables / Linux kernel Firewall(not d)
===Bash
=====Bash command line shortcuts
=====Bash Shell
=====Bash Scripting
===Nginx
===Networking
====Ports checks




===General
check linux distro:
  uname -a - returns info about kernel and stuff
  cat /etc/*-release - return info about distro
  lsb_release - command that returns info about distro
  cat /proc/version - file with linux version info

directories structure:
 / - root
 /bin - binaries for system boot, goes with distro
 /boot - kernel boot files and RAM disc with drv 
  for boot, and boot program itself
  /boot/grub/grub.conf - boot config
  /boot/vmlinuz - kernel
 /dev - all devices are here
 /etc - configs all here
  /ect/crontab - cron config
  /etc/fstab - mounts config
  /etc/passwd - users list
 /home - contains all users' dirs
  ~/bin - bins of particular user, add to PATH to use
 /lib - shared by various programs libraries(DLLs), probably for /bin's
 /lost+found - if HDD feels bad, some stuff could appear here
 /media - user-related mount points for flash, hdd, cd etc 
   which are mounted manually
 /opt - optional installed software and other stuff
   mostly used for commercial software
 /proc - files to peek at kernel things
 /root - root's home dir
 /sbin - same as /bin
 /tmp - temp used by various programs, could be cleaned at boot
 /usr - programs and files used by users
 /usr/bin - programs from distro, almost everythign already installed goes here
 /usr/lib - shared libraries for /usr/bin programs
 /usr/local - empty by default, available for all users on system
  /usr/local/bin - locally compiled\created bins should go here
  /usr/local/sbin - locally created system bins for administration
 /usr/sbin - System bins, come with distro, i suppose
 /usr/share - shared stuff(configs, files, images) except shared libs
 /usr/share/doc - mans for installed soft go here
 /var - variables, most changed dir, contains DBs, buffers, emails
 /var/log - all logs go here
 

man:
  man [section] <command>
  man sections:
   1. General commands
   2. System calls
   3. C library functions
   4. Special files (usually devices, those found in /dev) and drivers
   5. File formats and conventions
   6. Games and screensavers
   7. Miscellanea
   8. System administration commands and daemons
  Example:
   man 2 stat - will display manual for hashed 'stat'
	man has stat(1) and stat(2), which are different commands..

apropos:
  searches through man by keyword and returs matched in format:
   article (secion) - line matched

echo:
  accepts input from params or STDIN and returns in expanded to STDOUT
  accepts multyline input, and will return it in the same manner:
   echo "this is firstline
	this is second line
	this is third line"
   Params:
  -n - supress new line after output, like '.Write()' vs '.WriteLine();
  -e - enable interpretation of \ escaped stuff

whatis:
  returns first line from man of given command
   Example:
  dos:~$ whatis ls
  >ls (1)               - list directory contents

info:
  same as 'man' for GNU software

pwd:
  print working directory 
  returns string with current path location

cd:
  change directory
   Params:
  <path/to/folder> - changes dir to the folder
  -/<none>   - changes to current homedir
  ~username - changes to username homedir

ls:
  list files in given directory or current one
   Params:
  -l - long format (list basically)
    Columns:
    access rights | hard links qty | owner | owner group | 
    | size | data changed | name
  -a - show all files including hidden 
  -d - show only current directory, if given another directory - shows only it
       if given a wildcard that will match directories only - will return only
       the directories, w/o -d it will return every directory and its contents
	Example:
     ls -lda */ - will return list of directories
	Example:
     ls -la */ - will return contents of each directory within a separate list
  -r - reverse sorting order
  -S - sort by size
  -t - sort by date changed
  -F - adds slash to dirs in list
  -h - human readable sizes (mb, gb etc)
  -i - inode number, address where contents is located, same for all hard links

locale:
  displays all Locale related env variables, like
   LANG - set up during installation, picks install language
   LC_MONETARY - currency? 
   etc.

time:
  seems like calculates time of how long command takes to execute
  like StopWatch
   Syntax:
  time <command\script_name>
   Example:
  time some_script.sh
  > real 0m14.169s	#i spend 14 seconds (script uses 'read')
  > user 0m0.005s	#this two seems to calculate actual time of
  > sys	 0m0.005s	#+ calculations required, except manual intput

date:
  returns current date - weekday, day, month, year, time, time-zone
   Could be formatted like:
  date +"%x %r %Z"
   where
   x - short date in American format like '20.02.2019' - dot delimited
   r - time hh:mm:ss (dunno whether its 12 hours or 24 hours format)
   Z - short name of time zone like 'EET' for Eastern European Time

cal:
  calendar, spans for several lines , looks like ok calendar

file:
 short info about a file, file type etc.
  Linux does not have extensions for files so this is 
 the sure way to acquire such info

grep:
  Global Regular Expression Print
  filters output using regular expressions
  grep <params> <regex> <filepath>
  -v - inverts results
   ps aux | grep bash |grep -v grep - will return only real bash w/o grep 
	process listed
   '[b]ash' will also do the trick, dunno why
    why it works: 
     https://askubuntu.com/questions/153419/how-does-this-tricky-bracket-expression-in-grep-work
    TL;DR - basically string 'grep [f]irefox'(returned by ps aux) will not be 
	matched by regular expression '[f]irefox' (executed by grep)
  -i  - case INsensitive
  <filepath> - is not required if used in pipe
  -c - Count matched lines, return number of lines matched
  [] = search for a character
     i.e.: grep [abzfh] file - will search for appearance of any character 
		between square brackets in the file, standard regex
  -f <filename> - pass contents of filename as a pattern
  -l - search inside file contents and returns names of files found
  -L - like -v but for -l - show only not matched files
  -n - line number for matches
  -h - no file names in output 
  -r - recurse search in a directory
      i.e.: grep -lr cron /etc - will return all file names which content has
			'cron' pattern in whole /etc directory
  -E - extended regular expressions, same as 'egrep'
  -F - Fixed grep, same as 'fgrep'

fgrep:
  interprets regex special symbols as usual ones, and searches text with it
  searches FAST and simple
   fgrep ^hello file.txt - will find for literal '^hello' and not for hello at
			the beginning of the line in the file file.txt

egrep:
  allows to use Extended regular expressions
   accepts same Parameters as regular 'grep'
  it allows signs as:
   | ? + .* {} 
   {3} - match 3 times exactly
    Example:
  egrep 'AAA|BBB|CCC'   - will match either AAA BBB or CCC
  egrep '^(AAA|BBB|CCC)'   - will match either AAA BBB or CCC on the beginning
	of the line


stat: 
  returns status info about given file, if it dir, or file, when it was changed,  its size and stuff
   man 2 stat - for details

find:
  find <path> <params> <name mask>
   !!!	ORDER IS IMPORTANT
   Example:
  find / -type f -name "one.tx*" <-ls>

   Operations:
  -ls - will output results as in 'ls -l'
  -delete - delete found file. Better check first with -print, then -delete
  -print - prints full path to stdout, Default operation
  -print0 - changes delimiter to null character (0 code in ASCII), useful for 
	filenames with spaces, when need to use another delimiter. 
	Together with 'xargs' with --null, will go fine:
	 find -name '*.jpg' -print0 | xargs --null ls -l
  -quit - quits after first match
  -regex - will search with regex, whole path need to be matched in order
	to find it:
	 Example:
	find . -regex '.*[^-_./0-9a-zA-Z].*'
	 will match whole path(.* at both sides), where files have spaces
	 (spaces are not in [^....] group - files in the group are acceptable
	 in a filename)
  -ok - ask before execution, same as exec, see below
  -exec command '{}' \; - executes a command for _EVERY_ match, so 100 matches
	is 100 times executed commands, substitutes found value in {}
	with ; as a command end delimiter.
	{} and ; are special for Bash, so need to be escaped by '' or \ 
	 Use + instead of ; in the end to concatenate results and execute 
	command just once
	 Also instead of + 'xargs' command could be used
 	 This could be helpful as command line has limit on arguments (xargs
	restarts when arguments limit is reached until everything done)
     Example:
   find . -name "test*" -exec stat '{}' \;
    will find files and folders and display results of hashed 'stat' for 
    every matched item
     Example:
   find . -name "test*" -exec stat '{}' +
    will do the same as above, but 'stat' will be executed only once with list
    of found files - stat testmatch1 testmatch2 testmatch3
     Example:
   find . -name "test*" | xargs stat

   Checks:
  -type f:
	d - dir
	f - file
	l - sym link
	b - block device (like /dev/sda)
	c - char device (also in /dev , dunno what it is tho)
  -name "name*" - name or wildcard in "" - to prevent bash expansion
  -iname "Name*" - case Insensitive
  -size nM:
	b - block, default,            512 bytes
	c - char(byte)			 1 byte
	w - words (two bytes)		 2 bytes
	k - kilobytes, block         1 024 bytes
	M - megagytes, block     1 048 576 bytes
	G - gigabytes, block 1 073 741 824 bytes
    Example:
   find . -size +10M  - will find with size more than 10 megabytes
   find . -size 10M - will find exactly of 10 megabytes
   find . -size -10M - will find with size less than 10 megabytes
  -cmin n - files\dirs with attrs\contents changed exactly n minutes ago
	supports +\ \- like -size
  -mmin n - files\dirs whos contents changed n minutes ago
  -cnewer name: files\dirs with attrs\contents changed later than 
	given file name
  -newer name: files\dirs with contents changed later than given
	file name
  -ctime n - same as cmin, but n*24 hours is used
  -mtime n - same as mmin
  -empty - will match empty files and dirs
  -inum n - search for files with inode n, useful to search for hard links
  -samefile name - works same with -inum
  -user name - files\dirs owned by given user
  -nouser - files\dirs owned by noone, like deleted user
  -group group_name - will search for files\dirs owned by given group
  -nogroup - same but for groups
  -perm 777 - search by permission

    Operands:
   Operands glues Checks\Operands and Groups of Checks:
  -and\-a - logical AND - default value
  -or\-o - OR
  -not\-! - NOT
  ( ) - group of Checks. Need to be Escaped, as per is special for bash.
	By default checks goes from left to right, so
    ORDER IS IMPORTANT
   Example: 
  find . \( -type l -or -type d \) -a \(-name "this" -or -name "that" \)
   Example:
  find . -type f -name "*.bak" -print
   all files with name *.bak will be printed
  find . -print -type f -name "*.bak"
   print everytghint

    Params:
  -depth - process files first, then directories, Default for -delete
  -maxdepth levels_number - how deep to dig
  -mindepth levels_humber - go that deep before perform search
	seems like value 2 will ignore current dir, and 1 will not
  -mount - do not search in mounted directories
	but still searches if explicitly set to search inside mounted dir
  -noleaf - do not optimize search assuming its Unix filesystem
	required for DOS\WIndows CD-ROM systems
	But works fine without in on NTFS, probably required for exactly CD?
  


   could search by: 
   -date:
	  https://www.cyberciti.biz/faq/linux-unix-osxfind-files-by-date/
   Ranges example:
	  -m\a\ctime - modification\acces\creatioin? time <+\ \-days> 
	  - m\a\cmin - minutes i.e.:
	  find . -mtime -1 -ls - find files modified less than day ago
	  find . -mtime +1 -ls - all filed modified more than 1 day ago
	  find . -amin 1 -ls - all files accessed exactly 1 minute ago
	  -newerXY ; where XY could be:
	    a – The access time of the file reference
	    B – The birth time of the file reference
	    c – The inode status change time of reference
	    m – The modification time of the file reference
	    t – reference is interpreted directly as a time
	   i.e.:
	   find . -type f -newermt 2017-09-24 -ls
	    will find all files modified on 24/sep/2017
	   
   	by type
	 f - file
	 d - directory
	 l - symlink and others
	by user:
          TODO
	by group:
	 -group <name_of_group>

        by permissions:
  -perm - find by permission like Read\Write\Execute
   it seems to be pretty similar to just '-executable' flag(switch?)
    find /usr -type f -executable  - like this
  details here http://www.tutonics.com/2012/12/find-files-based-on-their-permissions.html
  i.e.:
    find / -perm 644 - will match EXACT permission files, only that have 644
    find / -perm -644 - will match files with at least 644 permission
     -perm -u+rw,g+r,o+r - same as above, will match 654 and dont 634
    find / -perm /644 - will match all files that have at least one of 3 sets
     /222 - match will occur if either the owner, the group, or other have their            "write" bit set.
     -perm /u+w,g+w,o+w - same as above, where u-user, g-group, o-owner
     -perm /a+w - same as above where a-all + or = is same so: /a=w 

  could execute commands on what found:
   find ~ -iname test.txt -exec du -h {} \;
    search in home dir for test.txt, case Insensitive, execute du -h for each
    found file. SEE '-exec' in man
    {} - is where the each find result will be piped.
    find and copy:
    !use with caution!  find . -name "*.pdf" -type f -exec cp {} ./pdfsfolder \;
  !see man for lots of details
  NOTE: with Permission denied erros, and probably others
   clear output of found stuff could be redirected to file. probably STDOUT
   while STDERR will keep appear on terminal window

xargs:
  takes arguments for given command from stdin and executes given command with
   that arguments.
  If amount of arguments are more than a limit of command line xargs will 
   restart given command with what left of arguments list from stdin until 
   handle everything.
    Params:
  --show-limits - will display various limits on the system - command length,
	argument length, how many take the env vars, buffer size, etc.
  --null - accepts null symbol as delimiter, useful when filenames have
	spaces, and need to use another delimiter

   Example:
  find . -name "test*" | xargs ls -l
   will construct ls -l test1 test2 test3 .... and execute it

locate:
  find files by name.
   NOTE: not all distros have it preinstalled
  call 'updatedb' before use, to update database used by locate
  locate <filename> - will return path to file if found
   i.e.
  locate kernel | grep /usr - will find any file contains 'kernel' in its name
   and grep /usr so it will show up only those which are in /usr dir(matched by)
    Params:
  --regex - search with regex
    Example:
   locate --regex '(^/|^/usr/)[s]?bin/(dz|gz|zip)'
    will search in /usr/bin or sbin or /bin or sbin for files having dz or gz or
   zip in their names


update files:
 touch <filename> - will update access time of a file, or create new if none
 echo "" > <filename> - create\rewrite filename with blank line
 echo "text" >> <filename> - append existing file with line 'text'


update-alternatives:
  manages symbolic links i.e.:
   sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.5 1 - python3.5 as first list item
   sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 2 - python3.6 as second list item
   sudo update-alternatives --config python3 - will print the list and ask
	for number to point to for default usage, 2 will pick python3.6 for
	python3 entry
  See here: 
   http://ubuntuhandbook.org/index.php/2017/07/install-python-3-6-1-in-ubuntu-16-04-lts/

sort:
  sorts by alphabet by default
   Synopsis:
  Sort [option] file
   Params:
  -r - reverse
  -n - sort by numbers
  -b - ignore leading blanks i.e. '   a'
  -f - ignore case
  -h - sor human readable format, like 1M 1K 1G
  -k - key i.e. -k 1, or --key=1
	-k 5 (or --key=5) - use column 5
	 Example: ls -l /usr/bin | sort -k 5 -rn
	will sort files by field 5 (size) by Numberic and Reverse
	--key=1,1 - column from 1 to 1
	--key=2nr  - use second column to sort groups after first key
		    accepts short params after column num: b, n, r
	 Example: sort --key=1,1 --key=2n file.txt
	sorts by column 1(diapason is important), then sorts by second field
	numerically - will resort each just sorted group by second field:
	 abc 1   - w/o --key=2n this will be second line
	 abc 10
	--key=3.7 - column number.symbol number. Use b, just in case
	 Example: sort -k 3.7nbr > t.txt ... dates
	will sort by third column and 7th symbol in it, by year 01.01.2006 in 
	this dd.mm.yyyy format
  -m - merge sorted files i.e. sort -m file1 file2 file3 > merged_file
  -o - output to file i.e. -o=file
  -t - change separator, default is 'space' and 'tab'
	 Example:
	sort -t ':' -k 7 /etc/passwd
	will sort by 7th column using : as field separator

uniq:
  deletes duplicates from SORTED output
   Params: 
  -d - displays only duplicets (kinda inversion)
  -c - displays number of matches and line (displays all lines) 
	 Example:
	sort test.txt | uniq -c
	will return lines in format '<tab><duplicate count> <duplicate line>'
  -f n - ignore(forward to) n fields in each line, 
	delimiter is as in 'sort' but CANNOT be changed
  -i - ignore case
  -s n - skip n symbols in line
  -u - unique lines only
 
  !Note: to get comparable output use 'sort' otherwice could display stuff in a
	way whcih will be not comparable. see ls examples below 

   Example:
  ls /bin /usr/bin | sort | uniq | less - will display combined unique files in
	both directories, in sorted order
  ls /bin /usr/bin | sort | uniq -d | less - will display only duplicated files
	in both dirs, in sorted order

cat:
  concatenate, return file contents on screen. GNU
  cat <filename> <filename> - will return contents of both to screen
  cat <file1> <file2> >> <file3> - create new\append old file with joined
   contents of file1 and 2
  cat file.* > file - will combine lots of files
  cat > newfile - will create a new file and promt for input 
   Params:
  -A - shows all hidden\meta symbols
	^I - tab
	$ - end of the line
  -n - show line numbers
  -s - squeeze blank lines, leaves only 1 blank if 1+ exists concequently

less:
  pager, upgraded version of 'more' command
  lists output in separate 'window' does not adding history in the console
  ALSO could be used like 'unzip' to view archives

split:
  splits file into another files, like with collection variable
  split -l 2 <file name> -  will split the file by 2 Lines into new files named
			    xaa, xab, xac, etc.

ln:
  number lines, 
  number lines by pages(number from 1 on second page)
  number only regex matched lines (-b regex)
  add header(\:\:\:) and footer(\:) between body(\:\:)

fold:
  split lines in two if length is exceeded
   Params:
  -w n - n length of w until move to another line
   Example:
  echo "long line of text and stuff" | fold -w 6
  >long line 
  >of text an
  >d stuff

fmt:
  format text, like 'fold' but saves emtpy lines, spaces and tabs
   Params:
  -w n - how long line should be (same to fold) , but screws up spaces and tabs
  -c - unscrews up spaces and tabs
   Example:
  fmt -cw 50 text.txt
   will format file with lines of 50 long, saving empty lines and tabs

printf:
  format string, like String.format(). has no new line \n, gotta add it manually
  % - conversion specificator:
   s - string
     Example:
    printf "variable: %s; and another %s\n" var ano
    >variable: var; and another ano
   d - digit negative or positive (1 or -1)
   f - float, with comma - (1,1 > 1,100000)
   o - octal number (1-8, like 8 bites in 1 byte, or chmod 777)
	Example:
	 "octal 1 is %0 octal 9 is %0)" 1 9 > 1 .... 11
   x - hex number (1-9a-f < lowercase)
   % - escapes % (printf "%%")
   %50s - formated string max 50 chars wide
   

wc: 
  word count, returns number of lines, chars\bytes and words
   -l - count lines

head:
  returs top of the file - 10 lines by default
   Params:
  -n <num> - change number of returned lines

tail:
  returns bottom of the file - 10 lines by default
   Params:
  -n <num> - number of returned lines
  -f  - follow, will update file if any



ifconfig:
  displays current network interfaces
  part of the 'net-tools' package
   /etc/network/interfaces - for interfaces(5) changes

sed:
  text stream editor, using RegEx for search\edit in stream(STDIN) line by line,
  in a non-interactive way(all decisions made\given in command params)
  Reads from file or STDIN
  Writes into STDOUT or to file if given 'w <file>' param or redirected STDOUT
  Does not change original file content (-i will edit it)
  Does only 1 change per line by default, 'g' - global, will match more than 
  first occurance
  Also can just write something(matched) from stream into a new file
=   sed '' file.txt - will just print everything, same as 'cat'

See More: https://www.digitalocean.com/community/tutorials/the-basics-of-using-the-sed-stream-editor-to-manipulate-text-in-linux
https://www.digitalocean.com/community/tutorials/intermediate-sed-manipulating-streams-of-text-in-a-linux-environment

  sed <param> '<param1>/pattern/replacement/<param2>' <file>
  -n - supress default ouput
  '/p' - print , works with 's'
    sed -n 'p' file - will print every line of file
    sed 'p' file - will print every line of file TWICE
  '1p' - print first line (address range)
  '1,5p' - print from first to fifth line (address range) 
  '1,+4p' - print 4 lines from first(inclusively) (address range)
  '1~3d' - print every other line: first then skip until 3rd line and again
	print 1st line(drop counter)
  '/pattern/,/pattern/' - address range matched by patterns
	'/^START$/,/^END$/d' - will delete everything between lines START and
	END, and do that again for another 'START' (until EOF or 'END' line)
  'd' - delete
  -i - edits IN-place - edits given file
   -i.bak - creates baskup of original Edited IN-place file
  's/pattern/replace/' - Substitute given RegEx pattern with given word
	's_pattern_replace_' - will work if need to use slash inside fields
	  or any other character as far as all 3 are consistent
  's/pattern/(&)/' - & is match result, so it will replace matched text with
	() around this same text
  's/\(matchGroup\)/\1/ - \( is escaped to work as matching group, \1 is the
	referenced matching group
  '/w <new_file>' - Write changed lines into file - param2 group
  '/g' - Global, will not go next line until first match
   '/2' - Instead of 'g' will match only SECOND appearance of pattern
  '/i' - Ignore case
  '/G' - inserts blank line after each line
  '=' - inserts line with a number of line after each line
  '/pattern/s/' - matches and substitutes only in the line matched by pattern
	Pattern could be complex too i.e. '/^$/d' will delete all empty lines
	 where ^ - beginning of line immediately followed by $ - end of line
  '/pattern/!' - matches everything EXCEPT pattern
	'/^$/!d' - will delete everything except blank lines
  
     Example:
=   sed 's/parttime/fulltime/gw promotions.txt' team - will Substitute 
	everything found by pattern 'parttime' to new value 'fulltime' more than
	once a line and will Write lines
	that were changed into 'promotions.txt' in file 'team'
=   sed 'fulltime/w fulltime.txt' team - will write all matched by 'fulltime'
	pattern lines from file 'team' into file 'fulltime.txt'
=   sed -n '/pattern/p' annoying.txt - will print only line containing pattern
=   sed .... ... > /dev/null - will supress STDOUT, actually redirecting it 
	into void
=   sed '0,/parttime/s/parttime/promotion/' team - will replace First occurance
	of 'parttime' to 'promotion' in 'team' file
=   sed 's/<[^>]*>//' team - will substitute matched by expression pattern with
	nothing - // it is empty, so nothing. 
	Regex: <[^>]*> - matches HTML tags
=   sed -n 's/on/forward/2p' file - will print out only lines where replace 
	was done, and replacing only 2nd match in line
=   sed 's/^.*at/(&)/' annoying.txt - puts () around matched text
=   sed 's/and/\&/;s/people/horses' annoying.txt - substitues and to escaped &
	then substitutes people to horses in annoying.txt
=   sed '/^$/d' file - will delete empty lines(beginning of line followed by end
	of line) from a 'file'


tee:
  reads from STDIN and writes to STDOUT and File
  Overrides existing file by default , to append use -a
   Good for saving in the middle of pipe
  tee <params> file1 file2
  -a - append file
    Example:
  ls dir1 | tee file1 - will display ls on dir1 and write output to file1
  ls dir2 | tee -a file1 | less - display dir2 and append ls output to file1
	then moe along a pipe and 'less' with the same result as in file1
   
   
nl:
  number lines in text file. only numbering not empty lines


mkdir:
  creates dir
  mkdir <params> <path>
  -p - creates every unexisting dir along the path, return no errors
   mkdir -p /not_exist1/not_exist2 - will create both not existing dirs 
  mkdir <dir1> <dir2> <dir3> - will create 3 separate directories

wildcards(not a command:
 * - any number of symbols
 ? - any symbol
 [ab1,] - one symbold from a list (same to regex)
 [!ab1,] - none of listed symbols([^] in regex)
 [[:class:]] - one symbol from a class
  :alnum: - digits and letters (\w in regex)
  :alpha: - letters (similar to  Unicode character property class \p{L} in regex)
  :digit: - digits (\d in regex)
  :lower: - lowercase
  :upper: - uppercase

cp:
  copy stuff
  cp <params> <source1 src2 src3> <destination>
  cp -rf ../source/* .
   -r - recursive copy
   -f - overwrite everything 
   -i - will ask for overwrite
   -a - archive - keep original access rights and owners
   -u - if overwrite - will copy only newer files
   -v - verbose
   . - current directory with saving all the names and paths from source
  NOTE: to copy hidden files, those star with . , need to escape dot(.) as it is
  regular expression:
  cp /etc/skel/\.* . - will copy all hidden files to current directory
  ............/.* . - will not work
  ............/.*.* . - will copy '..' which is parent directory to current one

mv: 
  see cp: above , pretty same, except it moves\renames files

rm:
  remove stuff, does not delete dirs and not empty dirs w/o additinal params
  rm <params> <source>
  rm -r <dirname>
   -r - recursive, also deletes directory at the end
   -d - deletes EMPTY directory
   -f - force
   -i - interactive - will ask before do
   -v - verbose

ln:
  create hard link by default
  ln <param> <path> <link name>
  -s - create soft link
  
  Hard link: every file has 1 , create another one in different place
   it will has size of its name, and will point to place on HDD for original file
   File can not be deleted until all Hard links deleted.
   Note: ls -i will return memory block of a place where link points
    so file and is hard links will all point in the same place, thus having 
    same number next to it.
   ONly can be created in the same filesystem (disk drive)

  Soft link: upgraded hard link, could be created anywhere, orig file can be
   deleted > link will become broken

type: 
  returns how given command is interpreted
   Example:
  dos:~$ type ls
  >ls is aliased to `ls --color=auto'
   Example:
  dos:~$ type cd
  >cd is a shell builtin
   Example:
  dos:~$ type apt
  >apt is /usr/bin/apt




wget:
  non interactive network downloader
   Params:
  -q - quiet, turns off wget output
  -i file / --input-file=file - reads URLs from a file
   Example:
  wget -q https://packages.microsoft.com/config/ubuntu/16.04/packages-microsoft-prod.deb - will download .deb file in current directory w/o any output

curl:
  tool for view-download web pages and content
   -o - output, redirects output to a file, usefull when downloading files
    sudo curl -o /usr/local/bin/ecs-cli https://s3.amazonaws.com/amazon-ecs-cli/ecs-cli-linux-amd64-latest
     will download ecs-cli binary file from amazon storage into /usr/... path
   -s - silent, no progress or error output. BUT still displays url contents
    echo "$(curl -s https://s3.amazonaws.com/amazon-ecs-cli/ecs-cli-linux-amd64-latest.md5) /usr/local/bin/ecs-cli" | md5sum -c -
     will curl display md5 from amazon storage, w/o any other output, then
      will display path to local ecs-cli, which will go into pipe to md5 sum
      which will compare given md5 and md5 from file under given path, and will
      return OK if everything if fine

du:
  disk usage
  du <params> <file/dir name>
   Does not accept input from pipe, seems like
    use 'xargs'
  du -hs dirname
   -h - human readable
	Example:
       ls -d */ | xargs du -hs  - will display size of all subdirs of of 
				current dir
	Or:
       ls -d */ | xargs du -hs | sort -hr | head -20 - top 20 biggest dirs
	Or:
       du -sh */ | sort -hr  - du also accepts wildcards, so no need
				to use ls for supplying list to du
   -s - summary for every directory w/o listings its contents

diff:
  checks differences two files or whole directories
   could recursevly dig into dirs for diffs, and generate patch files with
  differences, to be applied by 'patch' command
   Params:
  -c - context diff format (easier to read than standard POSIX diff)
  -u - unified diff format (less text, even more easier)
   Example:
  diff packages.list packages.list2
    packages.list:
     pkg1
     pkg2
    packages.list2:
     pkg2
     pkg3
   POSIX compliant output:
    1d0
    < pkg1
    2a2
    > pkg3
    read output:
   < - only first file has pkg1, it was on the left in the params list
   > - only second file has it, and it was on the right

  -c output:
   *** pkg1.lst	2019-02-02 02:22:25.312819822 +0200
   --- pkg2.lst	2019-02-02 02:22:36.984692484 +0200
   ***************
   *** 1,2 ****
   - pkg1
     pkg2
   --- 1,2 ----
     pkg2
   + pkg3

  -u output:
   --- pkg1.lst	2019-02-02 02:22:25.312819822 +0200
   +++ pkg2.lst	2019-02-02 02:22:36.984692484 +0200
   @@ -1,2 +1,2 @@
   -pkg1
    pkg2
   +pkg3

   Symbols:
   (none) - line match
   -      - line removed from first file
   +      - line added into second file
   !      - line changed (only -c mode)

patch:
  'diff' generated patch apply
   generated patch file already has file names, so no need to say anything
  just apply:
   patch < patchfile.txt
  Just kidding - use VCS

bash history:
  ! - invokes the Bash history mechanism
    !echo - will display and execute latest echo from current shell history
	    if such exists, displays error if nothing found(event not found)
   inverts exit code of commands if with space:
    ! true; echo $? # 1 - means exit code 0 was changed to 1
   also inverts pipe exit code
    ls | bogus_command; echo $? # exit code: 127
    ! ls | bogus_command; echo $? # exit code: 0

unzip:
  utility to unzip files. Unzips in the current folder by default
   Params:
  -d - specify folder where to extract
  -l - lists archive contents, 'less' tool does the same

zip: 
  creates zip archive, could also create encrypted archives(with password)
  --encrypt - will promt for password during arch creation:
   Example:
  zip --encrypt archive.zip files
   Less secure example:
  zip --password (password) file.zip files
  
  NOTE: zip encyption is very weak, use additional or other encription like gpg

Encryption 
public private keys ssl , stuff
https://www.devco.net/archives/2006/02/13/public_-_private_key_encryption_using_openssl.php

Create CRS - certificate signing request (csr)
https://www.sslshopper.com/what-is-a-csr-certificate-signing-request.html
openssl req -new -newkey rsa:2048 -nodes -out servername.csr -keyout servername.key 

General info about Keys, Key Pairs, Key Storages and stuff:
https://info.townsendsecurity.com/definitive-guide-to-encryption-key-management-fundamentals#How-Encryption-Key-Systems-Work

gnupg: gpg:
  Gnu PG could encrypt documents, basically all files
   See docs for encription here:
  https://www.gnupg.org/gph/en/manual/x110.html

  basic example w/o using Public-key cryptography:
   gpg --output <encrypted_file.gpg> --symmetryc <file_to_encrypt> - this will 
	ask for passphrase and its done

rsync:
  Remote Syncs files\dirs locally or remote-local\local-remote
   Synopsis:
  rsync [-params] /source/path [/another/source] /receiver/path
   Source-Receiver could be:
  - local file or dir
  - remote file or dir [user@]hostname:/path/to/file
  - remote server rsync, URI - rsync://[user@]hostname[:port]/path/to/file
   Source or Receiver MUST be local, BOTH Remotes NOT WORK
    Params:
  -a - archive, recursive and saves files attributes
  -v - verbose
  --delete - remove files that are in Receiver but not in SOurce
  --rsh=<shell> - remote shell, i.e. ssh - will transfer files via network
	in secure way (secure ssh tunnel)
   Example:
  rsync -av --delete --rsh=ssh /etc /home /usr/local remotesys:/backup
    Will archive(recurse and save file attrs) with verbose output , deleting
    files absent in source dirs and present in remote:/backup, copy different 
    from source dirs files via ssh tunnel to remotesys network location under
    path /backup

tar:
  tape archive - collects all files in archive, with savin all permissions
   and user's ownership
  tar <params> <archive> <another_params> <source>
  tar -cvf name.tar directory
   -c - create
   -v - verify\verbose
   -f - files
   -t - view archive , or something like that
   -r - append regular file to the end of an archive i.e:
     tar -rvf uncompressed.tar mybkup/mytest.txt
   -z - zip. tells tar that working with zips and not archives; 
        used for zipping, unzipping, viewing zip,
          if 'czvf' - creates .gz archive, compress same as 'gzip'
          if 'tzvf' - lists zip contents
          if 'zxvf' - extracts zip contents
   -j - zup but with bzip2 instead of gzip
   -p - preserve permissions
   another params:
    !! could be anywhere in the command, before or after other params
    --exclude=filename - excludes filename/dir/type from adding to archive
      i.e. tar -czvf arch.tar.gz --exclude=file.txt source_dir/
      !! use relative path of tar archive itself! not system file path !!
      !! use path like 'folder/folder/file' w/ or w/o quotas, optional
      !! DO NOT use path like './folder/folder/file' - this will fail silently
  params could be used w/o dash, like 'tar tvf archive.tar'
  Unzip:
    tar zxvf <archive.tar.gz> <path>
   -z - unzips contents
   -x - eXtract it
   -v - verbose
   -f - files
   <path> - cold be empty for current location
  Could pass view output to grep to search for particular file

gzip:
  compress files. it looks for a file it can compress by default even w/o
   specifying its name
  gzip <filename>
  gzil archive.tar
   will substitute 'archive.tar' by 'archive.tar.gz'
  Could be called by 'tar' command using 'z' key, will works the same
   Params:
  -c - compressed output to STDOUT(console), original file is left untouched
  -d - decompress file, same as 'gunzip'
  -f - force compresses even if .gz with same name already exists
  -h - help
  -l - list files in archive, with compress ratio and orig sizes
  -t - test compressed file for integrity
  -v - verbose
  -1 - set compress ratio 1 to 9, where ()
	1 - fast and little uncompressed and (also --fast)
	9 - slow and super compressed (also --best)
	6 - default value

gunzip:
 g unzip, unzips .gz files
  -c - cat, same as in gzip - writes to STDOUT leaves original files unchanged

zcat: 
 shipped with gzip, is like 'cat' but with z
  could be used instead of:
 gunzip -c file.gz | less

zless: 
 shipped with gzip, is like 'less' but with z
  could be used instead of:
 zcat file.gz | less

zgrep:
 grep for search in .gz compressed files

lsblk:
   List Block Devices
  list all devices mounted and not
   Params:
  -f\--fs - list fylesystems

block device types:
 /dev/fd* - floppy drives
 /dev/hd* - hard drives
 /dev/lp* - printers
 /dev/sd* - SCSI, including PATA/SATA in modern kernels, flash and usb, digital
	    cameras, players and stuff. 
 /dev/sr* - cd/dvd

block device naming:
 old motherboards had 2 IDE channgels, with cable for 2 devices (master\slave)
 devices are named by alphabet
 partitions are named by numbers
 first channel master - a - sda
  first partition on sda - 1 - sda1
  second partition on sda - 2 - sda2
 first channel slave - b - sdb
 second channel master - c - sdc
 second channel slave - d - sdd

tune2fs:
  adjust filesystem params
   Params:
  - l <filesystem> - list file system info
   Example:
  tune2fs -l $(df / | grep '/' | awk '{print $1}') | grep 'created'
   will return Filesystem created date, means when system was installed
  because looking at name of '/' root filesystem

df:
  display all mounted devices with size\free\used\paths etc
    Stands for: Disk Free
  df -h - human readable sizes
  df / - will show info about root partition - where / is mount point

how to get block device name, partition, mount it and unmount after:
  tail -f /var/log/messages 	- open messages and follow
  #mount disk, recheck messages for something like:
  "sdb: sdb1"
  "sd 3:0:0:0 [sdb] attached SCI removable disk"
  fdisk /dev/sdb
   p 				- see all partitions
  mkdir ~/mounted_stuff
  mount /dev/sdb1 ~/mounted_stuff
  umount /dev/sdb

mount:
  mount drive (disk, usb, floppy etc)
  mount -o rw,remount /
   -o - dunno.. TODO
   rw - seems to be read\write
   remount - pretty clear at first glance
   / - what to remount

    Example:
   lsblk -f     - view all devices
   mount /dev/sda5 /path/to/mount/point - mount device
   umount /dev/sda5   - unmount (Notice N letter absent in commnad name)
    Example:
    mount ISO image
   mount -t iso9660 -o loop image.iso /path/to/mountpoint

  -a - mount all lines added to /etc/fstab
  
  /etc/fstab - config for filesystems
   read by fsck, mount, unmount
  lines from this file read during 'mount -a'.
   check man fstab for details. 
  simply add automount of HDD from old windows:
  LABEL=Juli      /otherHDD/Juli  ntfs rw,suid,exec,auto,user,async
  labels or UUID could be taken from 'blkid' command

fdisk:
  manipulates disk partitions tables
   Usage:
  fdisk <block device name>
   Commands:
  m - manual/help
  p - show all partitions
  l - list all known filesystems (use one in mkfs )
   Example:
  fdisk /dev/sda
  > m 	- see what could do
  > p 	- see all partitions of the device 

mkfs:
  create new filesystem
   Params:
  -t fylesystem type
   Example:
  mkfs -t ext3 /dev/sdb1

fsck:
  filesystem check and repair (lost+found dir will have repaired files)
   Example:
  fsck /dev/sdb1

genisoimage:
  creates ISO images
   Parameters:
  -o <file.iso> - output to
  -R - for long file names and access rights for files in POSIX style
  -J - similar long names but for Windows
   Example:
  genisoimage -o cd-rom.iso -R -J ~/cd-rom-files
   where cd-rom-files is a directory with files to be added into ISO image
  

scp:
  secure copy using ssh protocol
   could copy to or copy from remote location.
  copy to remote:
  scp <params> <file_path> <receiving_username>@<address>:<receiving_file_path>
  copy from remote:
  scp <params> <remote_username>@<address(ip\name)>:<remote_local_path> <path>
  params:
  -v - verbose  

sshd(openssh)
  daemon config location:
   /etc/ssh/sshd_config
  sftp enable switch is located there, could be commented out and sshd restart
  to disable it
   /etc/ssh/ssh_config
  some another config
  ==
  RSA keys for ssh authentication generation process:
  https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys-on-centos7
  ssh-keygen [-b 4096] - generates key pair into given path
  ssh-copy-id user@34.250.25.207 - copy pub rsa from local machine to remote
   for the user given further access will be w/o password(could ask passphrese)

ssh-keygen:
  Known hosts are stored in a file /home/<username>/.ssh/knonwn_hosts.
   There are only 1 RSA key is allowed for the IP, in case RSA key is changed, then 
  old one need to be removed, otherwise it will not allow ssh acces:
   ssh-keygen -f "/home/dos/.ssh/known_hosts" -R 172.17.0.2
  
  

sftp:
  secure file transfer protocol, allows to list dir contents
  built-in into OpenSSH server, which workks as sshd service(daemon) together
  with scp
  sftp <remote_username>@<remote_ipaddress_or_name>
 sftp has its own set of directory related commands:
 pwd - print work dir, returns current remote_dir
 lpwd - current local_dir
 cd - change dir, changes remote_dir
 lcd - local change dir, changes local_dir from sftp via OpenSSH daemon
 get - copy file to current local_dir
  get <remote_filename> <new_local_name>
 ls also works, ALIASES from bashrc do not work

shutdown:
 shutdown or reboot or halt etc the computer
  by default shutdowns in 1 minute, also could be scheduled:
   Example:
  shutdown "21:45" - will shutdown at 21:45
  shutdown "+25" - will shutdown in 25 minutes from 'now'
  shutdown - will shutdown as 'shutdown +1'
  shutdown now - shutdown now

at:
 need to be installed, daemon
 schedules to do something _at_ some time:
 There are three ways to use it:
  Example 1:
 echo "shutdown" | at now + 1 min - will execute what echo will return
  	at time of now + 1 minute - echo will return stuff in ''
  Example 2:
 echo "shutdown" > cmd.txt
 at now + 1 min < cmd.txt - it will redirect STDIN from cmd.txt , will read
	from there, and shutdown 
  Example 3: 
 at now + 1 min
 at> shutdiwn     - will wait for input in STDIN
 ctrl+d           - to exit, and wait given time before execute shutdown

  Time could be like:
 [[CC]YY]MMDDhhmm[.ss]
  Example: 
 at -t 201403142134.12 < script.sh
 

cron:
 task scheduler

 *     *     *     *     *  command to be executed
 -     -     -     -     -
 |     |     |     |     |
 |     |     |     |     +----- day of week (0 - 6) (Sunday=0)
 |     |     |     +------- month (1 - 12)
 |     |     +--------- day of month (1 - 31)
 |     +----------- hour (0 - 23)
 +------------- min (0 - 59)

 So, for example, this will run ls every day at 14:04:
 
 04 14 * * * ls
 
 To set up a cronjob for a specific date:
 
     Create a new crontab by running crontab -e. This will bring up a window of 
	your favorite text editor.
 
     Add this line to the file that just opened. This particular example will 
	run at 14:34 on the 15th of March 2014 if that day is a Friday (so, OK,
 	it might run more than once):
 
     34 14 15 5  /path/to/command        
 
     Save the file and exit the editor.
 
awk:
 stuff to worh with text, programming language kind of
  Example: 
 awk 'BEGIN {printf "title"} {print "line"} END {printf "end"}' textfile.txt
  this will print 'title'
  then 'line' for every line in textfile
  and print 'end' at the end

 check out tutorial here:
 https://www.tutorialspoint.com/awk/awk_basic_syntax.htm

 workflow is Read, Execute, Repeat with tear up and tear down executed once:
 BEGIN
  Read line
  Execute user code
  Repeat if not EOF
 END

 Begin block executes only once, Tear Up, syntax:
  BEGIN {awk-commands}
 Optional
 
 Body block, which is actual stuff to do for every line matched by pattern:
  /pattern/ {awk-commands}
 Pattern is optional

 End block executes only once, Tear Down, syntax:
  END {awk-commands}
 Optional

 Also gets input from a file:
  -f <file_path>
    Example:
  command.awk:
   BEGIN {printf "start\n"}
   {print}
   END {printf "end\n"}

  awk -f command.awk textfile.txt   - this will read from command.awk and print
   'start' at 1st line
   then print every line
   then print 'end' and the latest line
 
 
===general


===Env Vars / Environment variables:
printenv:
env:
  very similar, prints environment variables to STDOUT
  printenv VAR - prints value of specified variable to STDOUT

  Useful Env variables:
  EDITOR - default text editor
  SHELL - name of the shell
  HOME - home path
  LANG - chars and sort order for language
  OLD_PWD - prev work dir
  PWD - current working dir
  PAGER - program for page view ( i.e. /usr/bin/less)
  PS1 - current prompt string value
	Example:   dos:~$: / root:~#:
	Prompt string could be drastically changed
	even including redraw of clocks in the cmd on every command entered
        Example: \[\033[s\033[0;0H\033[0;41m\033[K\033[1;33m\t\033[0m\033[u\]<>$
  TERM - type of the terminal
  TZ - time zone, usually *nix has Coordinated Universal Time , and it
	is corrected with current time zone upon display
  USER - username
  HISTCONTROL - with =ignoredups - will ignore duplicates in bash history
  HISTSIZE - changes default 500 value of history line-length

set:
  prints ALL variables - Shell vars, local vars, shell functions
  Builtin so use 'help set'


 Read more of set and printenv\env here:
https://www.digitalocean.com/community/tutorials/how-to-read-and-set-environmental-and-shell-variables-on-a-linux-vps
 Read more of printenv\env history here:
https://unix.stackexchange.com/questions/123473/what-is-the-difference-between-env-and-printenv

How to set\export env variables in bash:
  export - share variable for child processes started from current shell  
   Example:
  TEST=1 - will create var for current shell, will not be visible in processes
	started from the shell
  export TEST=1 - will create var for cur shell, and share it to processes
	started from the shell
  echo 'export TEST=1' >> ~/.bashrc - will create var at every non-login start 
	of the shell, if .profile reads .bashrc - login shell also get it
	 Usually for vars there are different file, which bashrc will read
	see/update local .bashrc to do so.
 	 Just exported into bashrc vars will not be visible until shell restart
	or source load:
	 source ~/.bashrc - will add newly exported vars into current session

Read export\env differences here:
 http://hackjutsu.com/2016/08/04/Difference%20between%20set,%20export%20and%20env%20in%20bash/

  Set variable ONLY for current shell:
  varname="my value"
  Set variable for current shell and ALL PROCESSES started from current shell:
  export varname="my value"
  For below LogOut is required:
  Set var PERMANENTLY for current user
  ~/.bashrc - add 'export varname="my val"' here
  Set var permanently and SYSTEM WIDE (all users/all processes)
  /etc/environment - add line 'VARNAME="my value"', caps bcs of naming convents
		     'export' is not userd here parser does not know it
  LogOut is required for permanent changes.
  
  Unset:
  unset ENV_VAR
  echo $ENV_VAR - returns nothing , bcs it is unset

  ALSO has options:
  set -o - will display all the options
   one of the options is 'noclobber'
   set -o noclobber - prevents '>' redirection from overriding files
   set +o noclobber - removes noclobber back


execute:
source:
dot (.):
  read more:
  https://superuser.com/questions/176783/what-is-the-difference-between-executing-a-bash-script-vs-sourcing-it/176788#176788

  execute script if it has x permission
  !! CREATES NEW SHELL !!
   ./script - script in current directory(./ dots lash notaion)
   script - execute script if it is in PATH var

  source script even if it does not have x permission
  documentation:
  http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#dot
  !! DOES NOT CREATE A NEW SHELL !!
  Executes commands from a file in the CURRENT environment. 
  In case it is for login-shell, it will update whole command line, probably
   not sure how it will work in case of 'su -'

   source myscript - myscript is param for source so no matter myscript is in
 		     path or not.
		     Still need to be valid shell script(#!/interpreter/pat)  
   . myscript - 'source' is alias for . in bash, syntax from POSIX 

  Source saves stuff changed in script(i.e. Env var updates) to the current 
  shell session where as Execute creates new session where changes are saved
  and kills it after everything is done - basic behaviour of everything





===User\Groups Management

=====User\Groups Management General info
group related info is stored in
  /etc/group   - file, use 'vigr' for edit
user related info stored in 
  /etc/passwd  - file. in case of edit use 'vipw' like 'visudo' with sudoers
default homedir files are stored in
  /etc/skel/   - directory
		 those files will be copied to user home when it is created
  ..../.bashrc - executed by bash for non-login shells - every time bash
		 is started interactively(from command line, which is also bash)
see more: https://unix.stackexchange.com/questions/129143/what-is-the-purpose-of-bashrc-and-how-does-it-work
  ..../.profile - executed by command interpreter for login shells
		  is not read if '.bash_login' or '.bash_profile' exists
		Usually also reads /etc/bash.bashrc
  ~/.profile - for login-shells also reads ~/.bashrc
  ..../.bash_logout - executed by bash when login shell ended


unlike files in /etc/skel changes to this files will affect even existing users
changes from here will be applied with every re-login to every 
		user on thesystem:
/etc/bash.bashrc -  will affect ~/.bashrc 
/etc/profile -  will affect ~/.profile

/etc/login.defs - useradd/userdel/usermod config
/etc/adduser.conf - adduser config(Ubuntu)
/etc/shadow - secure account info - passwords
/etc/gshadow - secure group account info - passwords

/etc/passwd:
root:x:0:0:root:/root:/bin/bash
root - username
x - placeholder for a password, modern systems use /etc/shadow file for pass
0 - is the user ID(UID) for this user
0 - is the group ID(GID) for this user
root - comment about this user
/root - home directory for this user
/bin/bash - default shell for this user(after he logs in presumably)
	    Possible values:
  /bin/nologin - deny login at all
  /bin/false - deny login but still can be logged in using 'su' command from 
		another account


/etc/group:
wheel:x:10:centos,user
wheel - group name
x - place holder for a password, modern systems use /etc/shadow filr for pass
10 - group id(GID) for the group
centos,user - users in the group, and probably user wheel too
   user along with who group was created id not listed in the group..
   probably to make sure group do or does not contains it , could try check
   groups of that user like 'groups wheel' - it will return 'no such user' if
   there is no user with same name as a group

NOTE: there are Primary group for a user and SUpplementary groups, 
  Primary is the first group of a user, others are suppplementary:
    $ groups johnny
    > johnny : test1 john newgroup1 newgroup2
  to add extra supplementary groups use 'usermod -a -G group1,group2'. 
  To change Primary group use  'usermod -g john johnny'
    > johnny : john newgroup1 newgroup2
  NOTE THAT 'test1' group has been removed at all, and not moved to 
   supplementary groups
  NOTE to change to test1 w/o deleting it user 'newgrp' command:
    $ newgrp newgroup1
    > newgroup1 john newgroup2
  Files created by user are owned by PRIMARY group of the user


=====user\groups management general info end

=====Manipulate Users And Groups
useradd:
  old since any *nix creation. Almost everything need to be done manually bcs of
  compatibility - different *nix platforms handles users differently, their ~
  directories could be different
  useradd -<params> <username>
  -d <~_path> - use if home name\path differs from default location, i.e.:
		 
	useradd -d /home/accounts/john testuser
  useradd -c "John from Accounts" -m -s /bin/bash john
   -c - adds a COMMENT in the /etc/passwd for this acc
   -m - MAKEs the home directory for this user, like /home/john
   -s - assigns the SHELL for the user
   john - actual user name
    user 'john' is the member of group 'john' and this is his PRIMARY group
  also:
   -u <UID> - user ID , first free picked (from range in config) id no specified
   -g <GID\Name> - assign to already existing group. i.e. -g accounts
   -G <GID\Name> - additional group. i.e. -G employees
   -e <YYY-MM-DD> - EXPIRATION date of the account
   -k </path> - sKELETON directory if differs from /etc/skel
   -p <hashed_pwd> - encrypted password for acc, or use 'passwd' command later
   
NOTE: after user is created the password need to be added:
passwd testuser

=====Manual User Creation
user# sudo su -		- become root
root# vipw		- edit /etc/passwd
 add new line with user info like:
 username:x:UID:GID:comment:/home/username:/bin/bash
root# vigr		- edit /etc/group
 add new line with user group info like:
 usergroup:x:GID:
root# cd /home && mkdir username - create user's home folder
root# cp -rf /etc/skel/\.* /home/username/. - copy everything from skel
root# chown -R username:usergroup username/ - change recurse ownership of dir
root# passwd username - create password for the user
=====manual user creation end

id:
  returns info of current user - id, main group id, other groups, etc.

groups:
  list groups of a user
  groups [username]
    w/o params gives current user groups
    with username - gives groups of that user

getent:
  getent group <$(whoami)>
  lists all groups on system and users of those groups(similar to /etc/group)

usermod:
  modify existing users
  usermod [<params>] <user>
   -l - change LOGIN of the user. i.e.:
      usermod -l johnny john - change username john to johnny
   -d - DIRECTORY path for New home directory of the user
   -m - MOVE-home dir to new DIRECTORY path
      usermod -m -d /home/johnny johnny - creates new dir for the user and moves
	everything from old dir to new dir
   -g - change primary GROUP
   -G - add to other GROUPs delimited , and no spaces adds, more groups for user
	will overwrite other supplementary groups except primary
   -a - APPEND groups, used with -G, to append existing supplementary groups:
      usermod -a -G newgroup1,newgroup2 johnny - will add two groups to the
	end of the list of a groups user have
   -L - LOCK user
	after lock there will be exclamation mark in /etc/shadow file before
	user passwod:
	johnny:!$6$DQMYnvhr$xKMYZSorH2wePlAunWDBKYWYSK8bmnyKMbr9IAuMoykPl7....
   -U - UNlock user, and remove exclamation mark '!' before user passwd hash
  More to read at:
   https://www.tecmint.com/usermod-command-examples/

userdel:
  deletes user in old way
  userdel <username>
  -r - deletes home directory too

adduser:
  adding user
  shell around perl written useradd command, which is hard to use
   adduser <username>
  CentOS7, does not have adduser, it links it to useradd:
   lrwxrwxrwx. 1 root root 7 гру 14  2016 /usr/sbin/adduser -> useradd

  /etc/adduser.conf - config for this command, has default ids, default shell
			default home dir(/home) and so on
    detailed how adduser works on Ubuntu:
    https://askubuntu.com/questions/659953/what-is-ubuntus-automatic-uid-generation-behavior

groupadd:
  adds group
  info about groups is stored in /etc/group file, see General above for details 
   once group is created use 'usermod' to add users to it
  group [options] <group>
  -g - manually set GROUP id

groupmod:
  modify existing groups
  -g - change GROUP id
    groupmod -g 300 manager - change group 'manager' to have new GID of 300
  -n - change NAME of a group
    groupmod -n managers manager - change group 'manager' to 'managers'

  
passwd: 
  change password for current user
   or for given user
  passwd [username]
  located in /usr/bin/passwd - ubuntu
             /bin/passwd - centos/red hat
  has 'setuid' thing..


gpasswd:
  add\remove users from a group, set admins for the group, set password for
  a group
  gpasswd <params> <group>
  -a <user>  - ADD user to a group
  -M <user1,user2> - add MULTIPLE users, commadelimited w/o spaces
     gpasswd -M john,jane manager
  -d <user> - DELETE user from a group
     sudo gpasswd -d johnny newgroup1 - remove 'johnny' from 'newgroup1'
  -A <user> - add ADMIN user for a group, dunno what it is about.. TODO

newgrp:
  newgrp <groupname>
  Changes primary group of the user w/o deleting any groups
   could freely move between assigned groups 
  And asks for password(probably group password) if trying to set unassigned
  group as primary one

groupdel:
  delete group
  groupdel [params] <groupname>

setuid and setgid:
 setuid:
  Attribute of a file that allows unprivileged user to have level of permission
  of original owner of the file. 
  For example passwd executable is owned by Root user. But unprivileged user 
  could execute it and the passwd binary will made the changes into /etc/passwd 
  and /etc/shadow file(contains some related to passwords stuff too), and those 
  both files also are owned by root user.
  In the same time passwd used by unprivileged user accepts no params - means
  user can not change other users passwords
 setgid:
  Attribute of file\directory inherited byu sub dirs\files, so subdirs inherit 
  parent's attributes. 
  Gives access  equal to group owning the file to unprivileged user executing 
  the file.
  Unprivileged user executes file Under the privileges granted to the user group  owner of that file.

whoami:
 returns username of currently logged user

=====manipulate users and groups

=====Super User
/etc/sudoers - file where all the privileges set. has user accounts with 
		privileges, as well as some groups, 
		for Ubuntu: 
			admin - almost root
			sudo - as root
		for CentOS7: 
			wheel - as root
NOTE: this file must be edited through 'visudo' command, this will ensure safe
  changes including lock file on edit and so on

root access:
  should be disabled for remote login in sshd for security reasons

su:
  su - [<username>] - creates new session for a user, i.e.:
     su - user - log in under 'user' user
  log in as super user(root), need to provide root password i.e.: 
  su -
   - dash is used to call login shell and reset most of env vars, basically safe
     against env related exploits and overriden standard commands. see here:
  https://unix.stackexchange.com/questions/7013/why-do-we-use-su-and-not-just-su
  
  !!!!
  in case root pasword is lost here is how to recover it from recovery mode
  https://askubuntu.com/questions/24006/how-do-i-reset-a-lost-administrative-password
  UBUNTU by default installs with random root password so noone knows it,
   need to use SUDO 
  
  Another way to recover a root password is to add a user to a privileged group
   like 'sudo' or 'wheel' - this way user, using program 'sudo' can become root
   w/o entering the forgotten(random for Ubuntu) password:
  user# groups - make sure user is in sudo group
  user# sudo su -  - become root w/o entering password root's password
  root# passwd  - enter new password

sudo
  TODO
=====super user end


=====user\groups management end

===Processes and Services Management

top: htop:
  gives a list of processes and resources used by the OS
  Process could has a priority:
   20 - is the LOWEST priority
   -20 - is the HIGHEST priority
  PID number 1 is always 'init' command or 'systemd' in my case on ubuntu 16 and
  centos 7

general processes:
  all processes are spawned from process with ID 1, 'init' in manual or systemd
  in my case, for some reason
  so there is a PID which is Process ID
  and PPID which is Parent Process ID, so every process has parent, except PID 1  it seems

ps:
  by default returns processes run by my current user and current terminal 
  session
  ps [-[-]]<params> 
	   UNIX standards - -<params>
	   BSD standards - <params>
	   GNU standards - --<params>
	params could be mixed, but conflicts could appear
   a - list all processes that has terminal attached: ps a
   x - list all processes owned my you(same EUID as ps)
   ax - list all processes(less columns)
   u - user oriented format
   p <pidlist> (-p, --pid)- select process by id (or just PID, == --pid <PID>)
   -C <cmdlist> - select by command name(COMMAND column)
   t <ttylist> - select by tty
   U, -U, -u, --user - selects by user name or EUID(RUID for -U), different 
		selections by user , will output different stuff
   -j - jobs format
   j - job control format
   -H - hierarhy(tree\forest format)
   l - long format
   -l long format , -y good with this
   -f - full format listing
   f - ASCII art process hierarchy (forest)
   o, -o, --format - change columns format
  	i.e. ps -o pid,ruser=RealUser -o comm=Command - wil return 3 columns
		named PID, RealUser and Command, with values of standard colmns

  ps aux - returns all processes run by all users from all terminals
	    if user does not exist 'x' in case of UNIX format it could treat it
	    in BSD format
  ps axjf - formatted method of processes with parents in tree view

pgrep:
  process grep , could find process id (PID) by process name, like
  pgrep bash - will return PID of the bash process running somewhere locally

kill:
  for terminating the processes
  kill <param> <PID>
  each kills param has its number equialent
  -TERM\-15-  sends a Signal to a process (Term[inate] Signal), in other words
   it asks the application to call its Dispose method, to gracefully stop. i.e.
   kill 1292 or kill -15 1292 or kill -TERM 1292
  -KILL\-9 ask OS's Kernel to shut down the process even if the process(app) 
   does not respond for 
  -HUP - restarts process if possible, does not change PID
  -l - lists all the signals available with their names and numbers(minus SIG
   prefix)
  NOTE: only owner of the process(or root) could kill the process
  %JOB_SPEC - kills job with appropriate number
   Examle:
  kill %1 - will kill the job with JOB_SPEC [1]

 kill all processes:
  kill -9 $(ps aux | grep '/usr/lib/firefox' | grep -v grep | awk '{print $2}')
   $() will be expanded. if list is returned will iterate over every item
	in the list
   grep -v - invert grep results (excluding own grep process from ps aux)
   awk will print second column from the list - PID
	as per grep matched several lines(List de-facto) every line will be 
	rinted. And sent out of $() into kill -9 as argument

killall:
 kills all instances of the process
  Example:
 killall xlogo - will kill all instances of 'xlogo'

nice: renice:
  changes priority of the process
  nice is for new processes
  
  renice is for already running processes

  renice <priority> <PID> i.e.
  renice 10 1292 - will change priority of process 1292 to 10, and will display
   previous value of the priority 
  
  nice <param> <priority> <binary_path> i.e.:
  nice -n 20 /bin/bash - will start New(-n) process from /bin/bash binary, with
   priority of 20(the lowest one)
   
=====Service controllers


sysvinit, systemd, upstart
/usr/lib/systemd - systemd service manager working dir (new Rhel\Debian-like)
/usr/share/upstart - upstart service manageer working dir(old Debian\Ubuntu)
/etc/init.d - sysvitin service manager working dir (old Centos\Debian\Ubuntu)
Note: Ubuntu could has all three installed currently, unlike centos that has
initd but it wrapped in systemd


service: daemon:
  RHEL-like - systemd (moved from SysVinit)
	https://fedoraproject.org/wiki/SysVinit_to_Systemd_Cheatsheet
  Debian-like - upstart service (also adopted systemd)
  for Debian-like and RHEL-like systems its two different ways
   for Ubuntu since 15.xx it seems it is even more different..
  Debian-like:
  status <service> 
  start <service>
  stop <service>
  restart <service>
   where service could be like 'ssh' or 'cron'
  to disable\enable services in upstart services the .override file need to be
  created in the /etc/init directory. For instance to disable cron:
   ensure cron exists:
   /etc/init/cron.conf - should exist
   echo "manual" > /etc/init/cron.override - will create text file with word
    'manual' as its only contents
   now cron will not be loaded on boot
   to enable cron back - simply delete 'cron.override' file from /etc/init dir

  RHEL-like:
  systemctl start <systemd>
  systemctl status <systemd>
  -- restart\stop 
   where systemd could be like 'sshd' or 'crond' where d means daemon
  systemctl disable <systemd> - disable system daemon from starting on boot
   basically it will delete soft link from /etc/systemd/... directory which it 
   seems is monitored on Init and everything there is executed
  systemctl enable <systemd> - enable datemon to start on boot
   basically it creates soft link from real binary location of daemon file into
   /etc/systemd/.... directory where all the links for boot are stored

  Ubuntu since 15.xx
  service <service> status
  -- stop\start\restart
   where service could be like 'ssh' or 'cron'
  service --status-all - will return statuses of all the services
!!  TODO: 
   check how to enable/disable services on boot for this new stuff and check how
  it exactly called now
  it seems it also supports systemctl and disable\enable with same commands,
   but creating .override file in the Debian way

supervisor:
  lightweight services controller, available for both RHEL and Debian like
   distros. Could be used in containers instead of systemd or systemctl etc
  Manages processes, could restart and monitor them, require config file to
  operate
   See how to start several processes in Docker using this tool:
https://kuldeeparya.wordpress.com/tag/how-to-run-ssh-and-apache2-in-docker-container/

  config file:
	[supervisord]
	nodaemon=true
	
	[program:sshd]
	command=/usr/sbin/sshd -D
	
	[program:apache2]
	command=/bin/bash -c “source /etc/apache2/envvars && exec /usr/sbin/apache2 -DFOREGROUND”



===processes and services management

===Package management
=====Debian\Ubuntu

.deb - packages format

dpkg:
  dpackage - debian packages manager, fully console, installs only package
  -i - install a package
     only package , no dependencies - generate error with dependencies required
  -l - list of all installed packages(use grep for specific packages)
  -L <package> - list of all the files that were created during package 
		 installation
  -S <filename> - similar to 'yum provides' but only for Installed packages
		it returns list of all packages that contain the string:
		-S less will return also 'serverless' word.. 
	Another option is to use web interface on Ubuntu:
	https://packages.ubuntu.com/

aptitude:
  frontend of dpkg, GUI in commandline
   categories of packages, local, available etc, then all the packages by 
  categories. also displays info about each package
  Enter key to open\close category.
  g or u - install selected package

apt-get: apt:
  stands for Advanced Package Tool
   apt is merge of apt-get and apt-cache, for easier use, has not all functions
   but also has some additional functions
  main apt tool used to install or download packages
  reads dependencies, and could install all of them
  apt-get update - reads all the repos and updates the local packages cache
  apt-get install - installs package(s), list delimited by space
       or install <package-2.3.5-3ubuntu1> - installs particular version if
		    it is compatible with distro and stuff   
       install -f - will install .deb package with its dependencies
		    Fix Broken Dependencies:
			https://unix.stackexchange.com/questions/159094/how-to-install-a-deb-file-by-dpkg-i-or-by-apt
  apt-get upgrade - made after Update, upgrades all the packages installed to
		    latest updates
          -y - answer Yes for all questons automatically
  .. dist-upgrade - updates to next available supported distro, 14.04 to 14.10 
		    if 14.10 is not supported already then to 15.04 etc
  apt-get autoclean - cleans cache, which means freeing space on hdd

  apt search <pkg> - search for package
  apt list --<params> - lists available packages from repos
	   --installed - lists only installed packages
  apt show <package> - shows info about package(apt-cache's command)

  --dry-run - simulation, will display possible actions but not perform any

  apt-get check - what dependencies may be broken
  apt-get build-dep - exact build dependencies for particular app (it seems it 
		is not necessery to download them all for work though...)

  apt-get download <package> - downloads package(probably to current dir
			       or /etc/apt?) - but only package w/o dependencies
  apt-get changelog - package changelog, like version history

  /etc/apt/ - apt configs
   sources.list - config of the repositories, which are re-read during 'update'
   		  command execution
  /var/cache/apt - cache folder of apt
  ./archives - contain all the archives, could be removed by 'autoclean' command

apt-cache:
  support tool of apt used to work with apt cache(updated by apt-get cache 
  command)
  apt-cache pkgnames - list of all pkgs APT knows, not all could be downloaded
			installed or installable e.g. virtual pkgs
  ... search <package> - lists all packages that contain package name in its 
			 name or description
  ... show <package> - info about the package, like description in apptitude
  ... stats - info about local cache(packages related stuff) - could be shrinked
  	      by running 'apt-get autoclean' to delete useless stuff

apt-file:
  another extension for apt-get, is in different package, 
   need to be installed first

  apt-file update - updates its own caches, need to be run first
  apt-file find <pattern>  - alias for search, see below:
  apt-file search <pattern> - search packages for file matched by pattern.
		returns list of packages and paths where file was found;
		includes removed packages too
  apt-file list - similar to dpkg -L but package not need to be installed or
		fetched

=======Uninstallation
  apt-get remove <package> - removes package binaries, leaves configs in the 
		             system for future use by other version or another
			     reason
  .. remove --purge <package> - removes package and all the stuff package 
  .. purge <package> ^same^     created during install(SYSTEMWIDE configs, link
				etc)
		it will not remove:
		 -dependence packages , to delete orphanes use
			apt-get autoremove
			  or
			.. --purge autoremove (same - will remove configs also)
		 -NOT SYSTEMWIDE config files - user-specific files
			files in user's home dir, or .config subdirectory of 
			home, those could be hidde (starts with .)
  		 -doesn't reverse changes in already existing user-specific
		  config files
		 -doesn't remove 'gconf' and 'dconf' files or reverse any
		  configuration d\gconf changes
	existing SYSTEMWIDE configs also are not affected by neither purge or
	remove commands, those ones created by user or other packages. but 
	uninstalling package could sometimes affect such files and undone 
	something
  apt-get autoremove - removes all orphaned packages
  .. purge --auto-remove <package> is similar to autoremove
=======uninstallation end

=======Repository setup
  Due to regular use of secure stuff also make sure following packages are
  installed(use apt-cahce show <package name> or 'apt list --installed'):
   apt-transport-https - This package enables the usage of 
	'deb https://foo distro main' lines
	in the /etc/apt/sources.list so that all package managers using the
	libapt-pkg library can access metadata and packages available in sources
	accessible over https (Hypertext Transfer Protocol Secure).
	  This transport supports server as well as client authentication
	 with certificates.
   ca-certificates - list of PEM files of certificates approved by Certificate
	Authorities, some common trusted certificates. For instance it has
	certificates for Debian stuff and Mozilla stuff.. 
	TLDR:
	It is a list of default trusted SSL sertificates stored in PEM format.
   curl - tool for transfering data from or to a server via HTTP/S, FTP/S, LDAP
	and lots of other formats, except SSH, but it has SCP..
	Used to download GPG key from docker storage. Which is added then to
	local apt storage
   software-properties-common - adds additional command for APT repositories 
	management. Such as 'add-apt-repository'

  Add gpg key:
	curl -fsSl https://download.docker.com/linux/ubuntu/gpg | sudo apt-key
	add -
	  Curl will download gpg key from docker , then pass it to apt-key (-) 
	and it will be added to local key storage
    make sure it is added, by searching for fingerpring:
	sudo apt-key fingerprint 0EBFCD88 - this will return OK if everything is
	fine
  Add a STABLE repository, it seems it is required:
	it is stored in:
	/etc/apt/sources.list - the file with the sources, where 
	add-apt-repository will add the repo by default
	/etc/apt/sources.list.d - directory where new file with a repo should be
	added, like in CentOS' yum
	add-apt-repository example:
	sudo add-apt-repository \
	   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
	   $(lsb_release -cs) \ - returns distro name
	   stable" - list of repos, test, edge could be added for docker

	Another example:
	sudo add-apt-repository ppa:jonathonf/python-3.7
	sudo apt-get update
	
   

=======List all installed packages:
  dpkg -l - list of packages and their details
  apt list --installed - list of full names
  aptitude - has a category for installed pkgs divided by categories

=====debian\ubuntu end

=====RedHat RHEL\Centos

  .rpm files
rpm:
  red hat package manager
  It seems it has some differend modes, where similar keys could exist with 
  different functions, i.e. -i - installation mode, -i in -q(query) mode is info
   the modes are:
   - install/update/freshen (first param -i)
   - uninstall (first param -e)
   - query (first param -q)
   - verify (first param -V probably)
   - set owners/groups
   - show querytags
   - show configurations
  Also it has general options, seems like it works with any mode
  if files or dependencies package need are absent installation of rpm will fail
  -q - query, probably 'what about something, like package requirements'
	single param will display package full name if it is installed or will
	say that it is not installed, i.e.:
!	rpm -q openssh-server - will return fill name if installed, like this
				openssh-server-7.4p1-13.el7_4.x86_64
   -p - package file
   -R - requires, lists package dependencies
  i.e.:
  rpm -qpR <rpm_package or package_name> - will list package requirements(depen
	dencies), if rpm_package name is given(xterm-123.3.rpm) - will check for
	package locally	if general package name is given(xterm) will look into
	remote repos
   -l - list files of the package, similar to 'dpkg -L' i.e.:
	rpm -ql openssh-server - will list all the files and paths of sshd
   -a --last - will list (a)ll the packages installed filtered by latest
   rpm -qa | grep nmap - will list all Installed packages, and grep nmap from 
		this list
   -d - documentation mentionings of a package 
   -f - some related to documentation param
   rpm -qdf <package> - return all documentation files where this package is
		mentioned
  -i - installation mode (fails if package installed of any version)
   -v - verbose (general parameter)
   -h - prints some hashes, looks better with -v
   -U - update package, BUT will install package if there is none installed
	if package is installed will not fail but update it(controversy to -i)
  rpm -Uvh <rpm_package or package_name> - will update or install package, 
	fails if there are missing dependencies
  -e or --erase - erase package, uninstall mode
   -v - short verbose mode, RETURNS NOTHING if no Verbose mode is passed
   -vv - very verbose, dunno why not -v
  -V - verify, there is some verification key for every package and rpm could
	check whether the package indeed has that key
   -a - all, same as for -a in Query mode of rpm tool 
   Keys could be imported from remote repos, or rpm could list all the keys
   that has been already imported
   rpm --import - will import key somehow from somewhere..
   rpm -qa gpg-pubkey* - will list all the public verification keys on system
  
yum:
  Stands for "Yellowdog Updater, Modified". yellowdog is already unsupported 
  version of Linux for PowerPC, which is also dead now
  yum <params> <package_name>
  Package management system
  yum update 
  yum upgrade - same as update - updates all the pkg repos and upgrades pkgs

  yum list [<pkg>] - displays if installed, version, and @updates mean that it
		   accepts updates. Package could be market to ignore updates
		   which probably means that yum update will not affect it
  ..  list installed - returns list of installed packages
  yum search <pkg> - searches for package, search in name and description
  yum install <pkg> - install package, and its dependencies
	-y - answer Yes for prompts automatically
  yum localinstall <pkg> - installs .rpm package downloaded to local machine
	will ALSO install needed dependencies, unlike 'rpm' tool
  yum info <pkg> - info about a package: descr, url, size, arch, etc
  yum check-update - checks which packages could be updated
     -C - use only local cache, doesn't update cache
  yum grouplist - YUM can group packages, this command displays all the groups
		  those groups will install bunch of packages
  .. groupinstall '<group name>' - will install all the packages from the group
  .. gropuremove '<gn>' - removes all the packages related to the group
  .. groupupdate '<gn>' - updates same stuff

  yum repolist - lists all available(enabled) repositories
  ..  .. all - lists all the repos disregard of their staus
  .. --enablerepo=<repoid from repolist> install <pkg> - enable a repo and
		install the package from that repo
  yum provides <feature or file> - Just use a specific name or a 
  	file-glob-syntax wild‐cards to list the packages available or installed
	that provide that feature or file.
  yum clean all - clears cache similar to apt-get autoclean
  yum history - history of yum - install\remove\upd package and stuff, sudo

=======Manage repositories
repos stored in /etc/yum.repos.d, which is a directory
to add new repository:
 create new file in the /etc/yum.repos.d dir named '<anything>.repo'

Format of repo file:
[dockerrepo]  - name of the repository section
name=Docker Repository - name of repo to display
baseurl=https://...    - address to where from do pulls of packages
enabled=1	       - repo is enabled inside my system
gpgcheck=1	       - enables gpg check
gpgkey=https://....    - location of the key


=======Uninstallation
  yum remove <pkg> - removes the package, doesn't remove its dependencies
!   yum autoremove <pkg> - also removes package, probably its deps too..
  To remove dependencies there are several ways:
  Option1: [probably should do this as standard]
  yum autoremove - removes orphaned dependencies, similar to 'apt-get utoremove'
  Option2: [probably could try this]
  update /etc/yum.conf file
   set
    clean_requirements_on_remove=1
   it is boolean value, which works on removel\update\obsoletion, goes through 
   each package's dependencies and deletes ones that are no longer required.
   default value False, could be 1,0,True,False,yes,no
  Option3: [probably better try not to use it]
  yum history undo <ID>
  basically in undoes the operation, that was performed during installation
  and thus removing the package and all the dependencies, and probably other
  stuff. 
  the only thing here is that i'm not sure whether it checks that package from 
  dependencies is dependent only by this package that caused them to be 
  installed, or not, so is not - it could end up with broken dependencies
  so how to do:
  yum history - check the ID column next to the command line with installation
  command of the package that need to be uninstalled
  then call 'yum history undo <ID>'
=======uninstallation end

=======List all installed packages:
  rpm -qa - query all packages, will return list of all installed packages
  yum list installed - will return list of installed packages


yum-utils:
  yumdownloader:
  yumdownloader <pkg>
    downloads a .rpm file, into current dir pretty similar to apt-get download
    command
=====redhat rhel\centos end
===package management end

===File Permissions / Ownership

! Linux treats everything - device\file\directory as if it is a FILE

drwxrwxrwx:
d - type of file(file\device\dir\link)
 r - read
   r only gives ability to list contents, but lots of ????? and file names
    can't even read files with 'cat' and stuff, need x permission for this
 w - write
 x - execute
   x only gives ability to 'cat' files, but cant ls into dir
    if file in such dir has only 'r' can even 'cat' it, if file has only x: cant
     cat it, need 'r' on file in dir with only 'x' to cat
   together with read - can ls norm and execute stuff like 'cat' to read file
first 3 - user permissions 
second 3 - user's group permissions
third 3 - all other users

chown:
  changes owner and group of a file\directory\link
  chown <params> [user][:group] <file/dir>
		 -reference=R_FILE FILE
  !!!! links could change owner of targeting file only!!!!!!!!!!
  -h \ -H - for changing owner of LINK not referenced location, see MANUAL
  -R - recursively change owners of nested directories
  -v - verbose, could be redirected to a file for future use, just in case
   in case of fucked up links
  could change only owner(<owner>), only group(<:group>), or both(<owner:group>)  could take ownership schema like owner:group from a file:
   chown --from=:user :otheruser file.txt

chmod:
  change modification
  chmod [<params>] <permissions> <file_path>
  text modifications:
  u - owner
  g - group
  a - all
  r/w/x - read/write/execute
  i.e.
  chmod a+rwx <filename> - give all the permissions of read/write/execute

  binary mode:
  4 - read
  2 - write
  1 - execute

  sum of numbers above will indicate permissions
  rwx = 4+2+1 = 7, and so on 

  Parameters:
  -v - verbose for every file processed
  -c - changes (less verbose), only when change is made
  -f - supress most error messages, --silent, --quiet
  --preserve-root - fail to operate recursively on '/'
  -R - recursive

lsattr:
  lists extra attributes of files on linux file system
  lsattr file1 - display attributes of the file1

chattr:
  changes extra attributes, lots of them, here some:
  i - immutable (can not be changed)
  a - appendable (can be opened only in append mode)
  u - undeletable
  syntax: 
  + - adds attribute
  - - removes attribute
  = - causes  selected attrs to be only attrs that files have..(not sure)
  i.e. 
  chattr +u file1 - adds undeletable attr to file1

===file permissions / ownership end

===IPTables / Linux kernel Firewall(not d)
read more:
https://www.unixmen.com/iptables-vs-firewalld/
https://linuxacademy.com/cp/socialize/index/type/community_post/id/15473

!!!!!!!!!!!!!!!!
!!  WHen using SSH configure SSH rules first BEFORE changing 
!!    the policies of the chains in the Filter table. 
!!  !!    TO DO NOT LOCK MYSELF OUT OF THE MACHINE  !!  !!   !!   !!
!!  CentOS 7 applies the rules right after entering the command
!!  even if Service IS stopped.
!!!!!!!!!!!!!!!

///Iptables is a tool to work with Netilter Framework, kind of firewall
/There are different services on different Linux distributions such as:
Ubuntu - ufw(Uncomplicated Firewall) service for Ubuntu, which uses IPtables
Centos7 - firewalld - firewall daemon which uses iptables
generic? - iptables-services - firewall service that uses iptables, generic 
	   it seems


Main three groups or something:
Tables:
 used to group different functionalities and separated in five:
 - filter - default table if no specified. Packet filtering.
   Built-in chains:
    - INPUT
    - OUTPUT
    - FORWARD
 - nat - used for network address translation(NAT)
 - raw - first table to check, configuring exemptions from conn. tracking
 - mangle - some specialized packet alteration...
 - security - Mandatory Access Control(MAC) networking rules
 -t\--table - parameter to specify a table

Chains:
 Tables contain set of chains.
 Chains group rules on different points of process.
 Chains could be Built-in or User defined.
  INPUT - Filter. input packets
  OUTPUT - Filter output packets
  FORWARD - Filter. going through packets
 -N\--new-chain - adds user defined chain
 -X (--delete-chain) - delete chain

Rules:
 Defined as a set of matches and a target. 
 Are listed in chains and followed by order until a match is found, then packet
 is handled by the target specified by the rule.
 -A (--append) - add new rule
 -D (--delete) - delete rule along with the chain in which is contained
 -L (--list) - list rules
 -S (--list-rules) - same list but in command format, as if the commands
		     that were used to add rule is saved and displayed here


 Matches:
   if match is true the packet will be processed by iptables.
   Following matches exist(not full list):
   -s (--source) - source of the packe(IP, hostname or network IP)
   -d (--destination) - destination of the packet(IP, hostname or network IP)
   -p (--protocol) - protocol(tcp/udp/all , all - default if none specified)
   -i (--in-interface) - interface that receives(left side of ifconfig output)
   -o (--out-interface) - output interface
   ! - Not. Match everything that is not in the match.

  Protocols has also its own matches, like 
   --dport - destination port(22 for ssh) is match for TCP protocol
  see full list of protocol related matches:
   iptables -p <protocol> -h - where protocol is tcp, icmp etc i.e.:
    iptables -A INPUT -p tcp -i eth0 --dport 22:25 -j ACCEPT 
      - adds rule to default table (-t filter) , appends Chain INPUT, matches:
	protocol TCP and interface eth0, protocol specific match port with
	range of ports 22 to 25. Rule's target if match is met - ACCEPT. 
	If not next rule will be processed until RETURN or end of rules, then
	Default TARGET(Default policy) will be applied.

 Targets:
  Determines the action to be taken if packet is Matched.
  -j (--jump) - specify Target
  There are 4 built-in Targets:
   ACCEPT - no checks , just accept packet
   DROP - refuse packet, do not send a response(simply ignore it)
   QUEUE - sends the packet to user space
   RETURN - returns to previous chain, or handle by Chain policy(Default?)

Default Policies:
  When packet is not matched by any Rule on the Chain - it is handled by the
  target specified in the policy of that chain.
  Two main approaches:
   Accept everything by default, and add rules to refuse access
   Refuse everything by default, and add rules for accept
  -P (--policy) <chain> <target> - set default policy for a chain with target


iptables:
  a generic table structure for the definition of rulsets
  basically ruleset of Linux kernel firewall
  it is a tool to get daemon(service) install other app:
   Centos - iptables-services
   Ubuntu\Debian - ufw(probably goes with iptables pkg)
   RHEL - iptables
   
  
  -L - list all rules currently installed on the system
  -A <section> - ADD

Service uses loads default config file when starts, applying some 
default rules, /etc/sysconfig/iptables for CentOS 7
  to manage a service:
   Debian/RHEL: sudo /etc/init.d/iptables start\stop\status
   Ubuntu: sudo service ufw start\stop\status
   Centos: servicectl start\stop\status iptables

IP address ranges:
CIDR blocks
https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation
https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#IPv4_CIDR_blocks

===ip tables / firewall

===Bash
=====Bash command line shortcuts
ctrl+a - moves cursor on the beginning of the line
ctrl+e - moved cursor on the End of the line
ctrl+u - removes everything from cursor position to the beginning of line
ctrl+k - removes everything from cursor position to the edn of the line
ctrl+w - removes previous word(space separated)
ctrl+l - cleares screen except of current command LINE
ctrl+p - last executed command shown in command line, same as UP ARROW key 
ctrl+c - terminate current process + exit\del current line by terminating it
ctrl+z - pause program, adding it to backgroud job. 'bg'\'fg' to continue run
history:
ctrl+r - bash history by typed command
ctrl+r - again looks one matched line upwards
ctrl+j - edit matched line
ctrl+o - execute current command from history

=====Bash Shell
alias:
 new aliasws workws only for current session
 alias <new name>="<command>" - adds command as alias
 alias <old name> - shows command
 alias - shows all aliases for current session

sleep:
  just regular sleep, stops current thread for amount of given seconds

  Experiments:
  sleep 10 & - will stop the thread for 10 seconds and move it to background

background: (not command)
  to start process in a background use & at the end
   Example:
  xlogo & - will start xlogo but cmd will return control to user
   xlogo will run as a Job, with 'Running' state

jobs:
  built-in command
  shows jobs in background, running, stopped
   More read:
  https://unix.stackexchange.com/questions/116959/there-are-stopped-jobs-on-bash-exit
   Params:
  -l - display PID

  NOte: kill could also accept JOB_SPECs to kill jobs, instead of PIDs

fg:
  moves job to the foreground
  fg JOB_SPEC
   Example:
  fg 1 - moves job [1] to the foreground
  Ctrl+z will move it back, but 'paused'- use bg to continue in background

bg:
  moves job to the background
   If program is 'Stopped' like after executiong ctrl+z shortcut, bg <%num>
  will continue its execution as a job, in the background
   Params:
  %job_spec - address numbered job

script:
  writes a session script - all executed commands and stuff
   with time parameter will create file with timings of each command and could
  play it afterwards using these two files

bash:
  man bash
  
  -c - accepts a whole bunch of commands like:
  /bin/bash -c "while true; do echo HELLO; sleep 1; done" - which will execute
	echo HELLO endlessly witn interval of 1 second.
	This even could be passed into a container:
   docker run -d ubuntu:xenial /bin/bash -c "...."


  could customize command prompt from default <user>@<hostname>:<path>$ 
  to something like <HH:MM:SS> <user> <whatever>!
   \t - 24 hour time format
   \w - full current path
   \w - current directory only
   \u - username
   \j - amount of running jobs
   \h - hostname

history:
  lists history, dumps .bash_history file into STDOUT, lines numbered
  -c - Clear history, but only in session, .bash_history remains the same
	only in CentOS it seems, ubuntu does nothing
   Example:
  history | grep /usr/bin - look for only what matched

which:
  shows location of a command and its alias if exists
   Does not show built-ins
  can search by alias too
  which <command\alias>
   i.e.
  which ll - will return alias line and path for binary

whereis:
  searches for binary file, sources, man files of the command
  Does not work with aliases!
   i.e.
  whereis pwd - will return path for binary and path for man page
   -b - search only for binaries

Streams and Redirects. redirection:
 Linux\Unix philosophy is that 'everything is a file' but in fact this are not
  files but block defices stored in /dev or /proc directories, and not files but
  some stuff stored in RAM for instance
STD - means standard
  Read More:
  https://stackoverflow.com/questions/3385201/confused-about-stdin-stdout-and-stderr
STDIN:
  I/O Stream
  file handle that process read to get info from user
  NOTE:
/dev/stdin is a symlink to /proc/self/fd/0 -- the first file descriptor that the
  currently running program has open. So, what is pointed to by /dev/stdin will
  change from program to program, because /proc/self/ always points to the 
  'currently running program'. (Whichever program is doing the open call.) 
  /dev/stdin and friends were put there to make setuid shell scripts safer, and
  let you pass the filename /dev/stdin to programs that only work with files, 
  but you want to control more interactively. (Someday this will be a useful 
  trick for you to know. :) 
STDOUT:
  I/O Stream
  process writes normal info to this file handle
STDERR:
  I/O Stream
  process writes error info to this file handle

  > - used to redirect STDOUT in cli to someplace else (i.e. file instaed of 
	console)
  2> - redirects STDERR
  >> - redirects STDOUT\ERR but file will not be overwritten, and appended 
	instead
  < - redurects STDIN, it will take data not from command line but from
	something else, i.e. a file
  cat /etc/passwd > /tmp/out     # redirect cat's standard out to /tmp/out
  cat /nonexistant 2> /tmp/err   # redirect cat's standard error to /tmp/error
  cat < /etc/passwd              # redirect cat's standard input to /etc/passwd
    or like this:
  cat < /etc/passwd > /tmp/out 2> /tmp/err

NOTE: redirect Standard Output(and error too) to null will hide it from everyone
  like this:
   ls secret_place >> /dev/null - will drop output into a void!!11
  Errors also could be hidden like this, in case of exposing of some secure or
  sensitive info

Redirect SDOUT and STDERR into two files in the same time:
  cat goodFile notExistingFile >mystdout 2> mystderr
	mystdout will contain standard output
	mystderr will contain standard error output

Redirect STDOUT and STDERR into single file:
  cat goodFile notExistingFile >mystdout 2>&1
	mystdout will contain both STDOUT and STDERR
    Or
  cat goodFile notExistingFile &> mystdout

noclobber:
  is an option set-up by 'set' command
   prevents redirection '>' from overriding files. it will return an error
  


pipe: |:
  redirects standard output of first program into standard input of another

expand:
  changes Tabs to Spaces in files from argument or stream from STDIN
   Example:
    cat -A test   >>> ^Ia ^Ia    a^Ia$
    expand test | cat -A  >>>        a       a    a  a$
  will change all tabs in file to spaces.

unexpand:
  change Spaces to Tabs - vice versa of 'expand'  

cut:
  Removes section from each line(column in fact) from a File
   Or parses each line in file by delimiter(Default is TAB) and could retreive
   only selected columns, or bytes - this is for -f option
  cut <param> <filename>
  See more: https://www.computerhope.com/unix/ucut.htm
  -d '<delim>' - change delimiter to <delim, ' - to prevent bash expansion of
	meta characters, if * or similar is delimiter. 
	-d ':' - safe way 
	  or
	-d: - will work too, but could fuck up a little
   Example:
  cut -f1 -d: passwd - will get only first field(-f1) from a file passwd
		fields are created by delimiting by colon(-d:)
  -b --bytes=LIST - cuts out bytes
  -c --characters=LIST - cuts out characters(in different encodings 1 character
	could be more than 1 byte, which is 8 bits)
	 Example:
	10/01/2007 - '-c 7-10' will cut out '2007'
  -f --fields=LIST - field to cut. or fields.
		uses delimiter(default TAB) to parse each line by it then
	it could return columns mentioned in the list by numbers from 1
	 Example:
	abc<tab>10.1<tab>10/01/2007 - '-f 3' will cut out '10/01/2007'
  How LIST works:
   !List of Integers
   !Starts from 1
   list of Integers, or range of integers, or multiple ranges, Separated by 
   commas. Selected columns is printed in the same order they were read,
   written to output exactly once(dunno what it means)
  N - the Nth byte, character or field
  N- - range from Nth byte,char,field to end of the line
  N-M - range from N to M as above
  -M - from beginning of the line till M
  -f Option:
  cut -f 1-2,4-5 data.txt - will cut 1st,2nd, 4th, 5th columns from data.txt
   --output-delimiter - changes delimiter in the output i.e.:
    cut -f 1,3 -d ':' --output-delimiter=' ' /etc/passwd - will substitute
	colon delimiter ':' to space ' ' in the OUTPUT of command for easier
	read
    ..... --output-delimiter=$'\t' - will substitute colon ':' for tab '\t'
	character, '$' here is for escapt
  -c Option:
   cut -c 3-12 data.txt - will cut from 3rd to 12th characters in the data.txt
		will not use delimiters at all
  -b Option:
   cut -b 3-12 data.txt - will cut rom 3rd to 12th BYTE, in case of ASCII 
		encoding it will be the same with -c as there 1 char == 1 byte

  Advanced example:
   grep '/bin/bash' /etc/passwd | cut -d ':' -f 1,6 - greps passwd file for 
	users that use /bin/bash as their default shell, and prints out 
	username and user home directory
	So cut accepts STDIN redirection

paste:
 vice versa of 'cut' - pastes columns in files

join:
 sql join but for text files
  in case of need to use this, use man\google, i'm to lazy to document
 Sorry.

bash escapes:
special symbols:
$'\t' - print tab, which is not printable character, same as /r/n or somehting

=====Bash Scripting
test:
 [ 1 -eq 1 ]    - ints compared with -eq, -lt, -gt, -ge, etc
 [ 'a' = 'a' ]  - strings compared with =, <, >, >=, etc
  tests condition, returns 0 if test is passed(true)

  -f <file> - file exists, aviode ~
  -d <file> - directory exists
  -h <file> or -L - symlinc exists
  -s <file> - exists and has size greater than 0
  -u <file> - exists and set-user-ID bit is set
  -k <file> - exists and its sticky bit set 
  -r <file> - file exists and with read permission
  -w <file> - file exists and with write permission 
  -x <file> - file exists and with execute permission
  -z <string> - length of string is 0

  Test could be performed from script , better to use braces [ . ]
  Also could be preformed right inside CLI, it will return nothing, so need to
  create manual then\else-like structures:
   test -f '/path/to/file name' && echo "exitcode: &?. True" || echo "exitcode:
 &?. False" - test for file existance, then if exit code 0 will execute second 
	echo with True, else (OR) will execute echo with False.
      &? -  will print exit code of previously executed command, which in this 
	case is 'test' command

  Test even can be performed w/o test itself:
    Example:
  curl -s google.com | egrep -ci '301 moved' > /dev/null && echo "file has moved
" || echo "false" - curl will pass STDOUT to egrep which will try to match 
	string '301 moved', if it succeed exit code will be 0.
	And first Echo (after &&) will be executed
	Else, egrep will return 1, and thus second echo (after ||) will be
	executed
  
for:
  regular for loop could be done in command line too

  for i in `command`; do echo $i; done
    backtick -  `, does the job, expression between it will be executed in 
	sub shell and its result will be returned, when we have a collection
	we could iterate it with FOR 
  for line in `cat file1`; do echo $line; done
	

===Other programs:

elinks:
  command line browser, with interface similar to MC or aptitude
  
mc:
  two-windowed GUI to work with file system


===Nginx
  fast web server, could be used as load balancer between servers(docker 
   containers) - reverse proxy server

  package name: nginx
  /etc/nginx - config(as usual in etc dir)
    ...conf.d - directory for some main configs probably
    ...default.d - directory for default configs
    ...sites-available - directory for available sites, convention directory
	does not exist by default
    ...sites-enabled - same as previous
	Read more about sites-* here:
	https://serverfault.com/questions/527630/what-is-the-different-usages-for-sites-available-vs-the-conf-d-directory-for-ngi

    Basically all the configs are included in main config:
    /etc/nginx/nginx.conf
	it includes all the configs from directories mentioned above
	same settings from different configs are overwritten by later added:
	first.conf(a=1, b=2), second.conf(b=4, c=3) will be treated like this:
	a=1, b=4, c =3
 !!! MAKE SURE to follow syntax !!!
	'upstream' directive can not be added before http{} section 
	or inside http{} section

	So all includes need to be made correctly
	also not all directives could be added into configs that are included
	because it could lead to conflicts and Nginx wont start
	
	IF nginx is not starting check:
	journalctl -xe - for service errors

	IF nginx throws errors or behave in not expected way check error log
	its location in nginx.conf file
	default location: /var/log/nginx/error.log

    Nginx could refuse connection:
	(13: Permission denied)
       this related to SELinux, which also has error log:
	sudo cat /var/log/audit/audit.log | grep nginx | grep denied
     SELinux has bool values that Nginx and Apache and probably others use
       getsebool -a | grep httpd - will return all bools related to httpd 
	and Nginx(it uses them too)
     To allow connections set:
	setsebool httpd_can_network_connect on - or use 1
	-P - will set it permanently
	

    Config setup, for proxy server:
    Option 1:
	create config with following stuff:

#pool for balancing? should be after http{} section
upstream containerapp {
        server localhost:8081; #- not sure whether localhost is fine
        server localhost:8082;
}

#server configuration
server {
        listen *:80; #everything coming to port 80

        server_name localhost;
        index index.html index.htm index.php #match any such file and use it

        access_log /var/log/nginx/localweb.log; #save logs here
        error_log /var/log/nginx/localerr.log;

	#location is root , for some reason
        location / {
		#pass traffic coming through port 80 into the pool
                proxy_pass http://containerapp; 
        }
}

     Option 2:
	Add upstream (with local network IPs) into nginx.config after http{}
	section
	Update server{} like above, but w/o *_log fields
	Server_name also use local network IP
	ALso i commented default 'root' not sure if this necessary


===Networking

networking relies on configuration files:
/etc/sysconfig/network-scripts/ifcfg-<interfase_name> - this file describes 
	how network interface works, every interface has its own file.
	Settings of the interface are stored in here
	 Example:
	DEVICE="eth0"
	BOOTPROTO="dhcp"
	HWADDR="00:0C:29:3B:44:D3"
	IPV6INIT="yes"
	NM_CONTROLLED="yes"
	ONBOOT="yes"
	TYPE="Ethernet"
	UUID="951b47f7-e9c5-4e64-85ce-44c79732d914"
/etc/sysconfig/network - general network configuration, probably
	 Example:
	NETWORKING=yes
	HOSTNAME=centos7
	GATEWAY=10.0.0.1
/etc/resolv.conf - something like 'hosts' in Windows, it seems, store default DNS here
	 Example:
	nameserver 8.8.8.8   - default google's DNS
see this for details on resolving Networking issue on VMWare:
https://superuser.com/questions/901672/centos-7-ping-8-8-8-8-connect-network-is-unreachable/901677


ip: 
  link - creates network interface with name and type:
	also could be used if 'ifconfig' is absent
	Example:
     ip link add br10 type bridge - will create network interface with 
	name br10 and of type bridge
   add - add interface
   set - sets interface, somehow
	ip link set br10 up - will enable network interface br10


  addr - manages ip addresses. 
	in case 'ifconfig' is not available this comes handy
   add - adds gateway ip and subnet mask for device with a name
	Example:
     addr add 10.10.100.1/24 dev br10 - adds gateway with addres ...100.1 
	and with subnet mask 255.255.255.0 to the device called br10
	which is a network interface

  Add persistant network interface:
	/etc/network/interfaces
	auto <interface name>
	iface <name> inet static
		address 10.10.100.1	#main address
		netmask 255.255.255.0	#class C, like 10.10.100.1/24
		bridge_ports dummy0	#some mock stuff
		bridge_stp off
		bridge fd 0 		#frame 0
====Ports checks
read more:
https://www.cyberciti.biz/faq/how-do-i-find-out-what-ports-are-listeningopen-on-my-linuxfreebsd-server/
https://www.maketecheasier.com/check-open-ports-linux/

netstat:
  find open ports
   Params:
  -l / --listen - displays ports that are in LISTEN state (lots of)
  -vatn - opened ports and established TCP connections
   - v - ?
   - a - All - show all sockets
   - t - TCP connections
   - u - UDP connections
   - n - short DNS hostname. will display dns names/ports w/o it
   - p - show related PID and Program Name
  Example:
   netstat -vat - display used porta and established connections

lsof:
  also checks ports, could display processes that are using
   port, and files used by the process

   Params:
  -i - displays processes and ports used, and connection
 	with friendly names
   - 4 - ipv4
   - tcp - display tcp (cant use 4 and tcp in the same time, it seems)
  
nmap:
  Network Mapped, detects open ports on my system
   -s - Scan, there are lots of it
    -sT - scan TCP
    -sn - disable port scan, just 'ping'
    -stuff, see 'man nmap'
   -O - OS detection
   -T - TCP
   -U - UDP

  NOTE: 
   Read MAN - it has examples and lots of stuff:
    scanme.nmap.org/24 - will scan 256 IP in C network class of
	scanme network - CRAZY!!111

  Example:
   nmap -sT -O localhost    - [s]cans [T]CP on localhost
 	

