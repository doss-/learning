==========TODO:
create bash script that will export variables to:
1. current session
2. user .bashrc file so it will be available in other sessions
3. system-wide

check distribution and update according files for
1. user-wide
2. system-wide 

do the same for Bash Aliases


Save this script into this repo

===
identify myself on git
==========todo

Contents
===General
===Env Vars / Environment variables:
===User\Groups Management
=====User\Groups Management General info
=====Manipulate Users And Groups
=====Super User
===Processes and Services Management
===Package management
=====Debian\Ubuntu
=======Uninstallation
=======Repository setup
=======List all installed packages:
=====RedHat RHEL\Centos
=======Manage repositories
=======Uninstallation
=======List all installed packages:
===File Permissions / Ownership
===IPTables / Linux kernel Firewall(not d)
===Bash
=====Bash command line shortcuts
=====Bash Shell
=====Bash Scripting
===Nginx




===General
check linux distro:
  uname -a - returns info about kernel and stuff
  cat /etc/*-release - return info about distro
  lsb_release - command that returns info about distro
  cat /proc/version - file with linux version info

man:
  man [section] <command>
  man sections:
   1. General commands
   2. System calls
   3. C library functions
   4. Special files (usually devices, those found in /dev) and drivers
   5. File formats and conventions
   6. Games and screensavers
   7. Miscellanea
   8. System administration commands and daemons

grep:
  Global Regular Expression Print
  filters output using regular expressions
  grep <params> <regex> <filepath>
  -v - inverts results
   ps aux | grep bash |grep -v grep - will return only real bash w/o grep 
			process listed
  -i  - case INsensitive
  <filepath> - is not required if used in pipe
  -c - Count matched lines, return number of lines matched
  [] = search for a character
     i.e.: grep [abzfh] file - will search for appearance of any character 
		between square brackets in the file, standard regex
  -f <filename> - pass contents of filename as a pattern
  -l - search inside file contents and returns names of files found
  -r - recurse search in a directory
      i.e.: grep -lr cron /etc - will return all file names which content has
			'cron' pattern in whole /etc directory
  -E - extended regular expressions, same as 'egrep'
  -F - Fixed grep, same as 'fgrep'

fgrep:
  interprets regex special symbols as usual ones, and searches text with it
  searches FAST and simple
   fgrep ^hello file.txt - will find for literal '^hello' and not for hello at
			the beginning of the line in the file file.txt

egrep:
  allows to use Extended regular expressions
   accepts same Parameters as regular 'grep'
  it allows signs as:
   | ? + .* {} 
   {3} - match 3 times exactly


find:
  find <path> <params> <name mask>
  ex:  find / -type f -name "one.txt" <-ls>
   type:
	d - dir
	f - file
	l - sym link
	-ls - will output results as in 'ls -l'
   could search by: 
	date:
	  https://www.cyberciti.biz/faq/linux-unix-osxfind-files-by-date/
	Ranges example
	  -m\a\ctime - modification\acces\creatioin? time <+\ \-days> 
	  - m\a\cmin - minutes i.e.:
	  find . -mtime -1 -ls - find files modified less than day ago
	  find . -mtime +1 -ls - all filed modified more than 1 day ago
	  find . -amin 1 -ls - all files accessed exactly 1 minute ago
	  -newerXY ; where XY could be:
	    a – The access time of the file reference
	    B – The birth time of the file reference
	    c – The inode status change time of reference
	    m – The modification time of the file reference
	    t – reference is interpreted directly as a time
	   i.e.:
	   find . -type f -newermt 2017-09-24 -ls
	    will find all files modified on 24/sep/2017
	   
   	by type
	 f - file
	 d - directory
	 l - symlink and others
	by user:
          TODO
	by group:
	 -group <name_of_group>

        by permissions:
  -perm - find by permission like Read\Write\Execute
   it seems to be pretty similar to just '-executable' flag(switch?)
    find /usr -type f -executable  - like this
  details here http://www.tutonics.com/2012/12/find-files-based-on-their-permissions.html
  i.e.:
    find / -perm 644 - will match EXACT permission files, only that have 644
    find / -perm -644 - will match files with at least 644 permission
     -perm -u+rw,g+r,o+r - same as above, will match 654 and dont 634
    find / -perm /644 - will match all files that have at least one of 3 sets
     /222 - match will occur if either the owner, the group, or other have their            "write" bit set.
     -perm /u+w,g+w,o+w - same as above, where u-user, g-group, o-owner
     -perm /a+w - same as above where a-all + or = is same so: /a=w 

  could execute commands on what found:
   find ~ -iname test.txt -exec du -h {} \;
    search in home dir for test.txt, case Insensitive, execute du -h for each
    found file. SEE '-exec' in man
    {} - is where the each find result will be piped.
    find and copy:
    !use with caution!  find . -name "*.pdf" -type f -exec cp {} ./pdfsfolder \;
  !see man for lots of details
  NOTE: with Permission denied erros, and probably others
   clear output of found stuff could be redirected to file. probably STDOUT
   while STDERR will keep appear on terminal window


locate:
  find files by name.
   NOTE: not all distros have it preinstalled
  call 'updatedb' before use, to update database used by locate
  locate <filename> - will return path to file if found
   i.e.
  locate kernel | grep /usr - will find any file contains 'kernel' in its name
   and grep /usr so it will show up only those which are in /usr dir(matched by)


update files:
 touch <filename> - will update access time of a file, or create new if none
 echo "" > <filename> - create\rewrite filename with blank line
 echo "text" >> <filename> - append existing file with line 'text'


ls:
  list files on the system
  ls -<params> <path+wildcards>
  ll - default bash alias which leads to:
   ls -la - Ubuntu
   ls -l - CentOs
  -l - list format
  -a - all, show hidden files


cat:
  concatenate, return file contents on screen
  cat <filename> <filename> - will return contents of both to screen
  cat <file1> <file2> >> <file3> - create new\append old file with joined
   contents of file1 and 2


split:
  splits file into another files, like with collection variable
  split -l 2 <file name> -  will split the file by 2 Lines into new files named
			    xaa, xab, xac, etc.


df:
  display all mounted devices with size\free\used\paths etc
  df -h - human readable sizes


ifconfig:
  displays current network interfaces
  part of the 'net-tools' package

sed:
  text stream editor, using RegEx for search\edit in stream(STDIN) line by line,
  in a non-interactive way(all decisions made\given in command params)
  Reads from file or STDIN
  Writes into STDOUT or to file if given 'w <file>' param or redirected STDOUT
  Does not change original file content (-i will edit it)
  Does only 1 change per line by default, 'g' - global, will match more than 
  first occurance
  Also can just write something(matched) from stream into a new file
=   sed '' file.txt - will just print everything, same as 'cat'

See More: https://www.digitalocean.com/community/tutorials/the-basics-of-using-the-sed-stream-editor-to-manipulate-text-in-linux
https://www.digitalocean.com/community/tutorials/intermediate-sed-manipulating-streams-of-text-in-a-linux-environment

  sed <param> '<param1>/pattern/replacement/<param2>' <file>
  -n - supress default ouput
  '/p' - print , works with 's'
    sed -n 'p' file - will print every line of file
    sed 'p' file - will print every line of file TWICE
  '1p' - print first line (address range)
  '1,5p' - print from first to fifth line (address range) 
  '1,+4p' - print 4 lines from first(inclusively) (address range)
  '1~3d' - print every other line: first then skip until 3rd line and again
	print 1st line(drop counter)
  '/pattern/,/pattern/' - address range matched by patterns
	'/^START$/,/^END$/d' - will delete everything between lines START and
	END, and do that again for another 'START' (until EOF or 'END' line)
  'd' - delete
  -i - edits IN-place - edits given file
   -i.bak - creates baskup of original Edited IN-place file
  's/pattern/replace/' - Substitute given RegEx pattern with given word
	's_pattern_replace_' - will work if need to use slash inside fields
	  or any other character as far as all 3 are consistent
  's/pattern/(&)/' - & is match result, so it will replace matched text with
	() around this same text
  's/\(matchGroup\)/\1/ - \( is escaped to work as matching group, \1 is the
	referenced matching group
  '/w <new_file>' - Write changed lines into file - param2 group
  '/g' - Global, will not go next line until first match
   '/2' - Instead of 'g' will match only SECOND appearance of pattern
  '/i' - Ignore case
  '/G' - inserts blank line after each line
  '=' - inserts line with a number of line after each line
  '/pattern/s/' - matches and substitutes only in the line matched by pattern
	Pattern could be complex too i.e. '/^$/d' will delete all empty lines
	 where ^ - beginning of line immediately followed by $ - end of line
  '/pattern/!' - matches everything EXCEPT pattern
	'/^$/!d' - will delete everything except blank lines
  
     Example:
=   sed 's/parttime/fulltime/gw promotions.txt' team - will Substitute 
	everything found by pattern 'parttime' to new value 'fulltime' more than
	once a line and will Write lines
	that were changed into 'promotions.txt' in file 'team'
=   sed 'fulltime/w fulltime.txt' team - will write all matched by 'fulltime'
	pattern lines from file 'team' into file 'fulltime.txt'
=   sed -n '/pattern/p' annoying.txt - will print only line containing pattern
=   sed .... ... > /dev/null - will supress STDOUT, actually redirecting it 
	into void
=   sed '0,/parttime/s/parttime/promotion/' team - will replace First occurance
	of 'parttime' to 'promotion' in 'team' file
=   sed 's/<[^>]*>//' team - will substitute matched by expression pattern with
	nothing - // it is empty, so nothing. 
	Regex: <[^>]*> - matches HTML tags
=   sed -n 's/on/forward/2p' file - will print out only lines where replace 
	was done, and replacing only 2nd match in line
=   sed 's/^.*at/(&)/' annoying.txt - puts () around matched text
=   sed 's/and/\&/;s/people/horses' annoying.txt - substitues and to escaped &
	then substitutes people to horses in annoying.txt
=   sed '/^$/d' file - will delete empty lines(beginning of line followed by end
	of line) from a 'file'


tee:
  reads from STDIN and writes to STDOUT and File
  Overrides existing file by default , to append use -a
  tee <params> file1 file2
  -a - append file
    Example:
  ls dir1 | tee file1 - will display ls on dir1 and write output to file1
  ls dir2 | tee -a file1 - display dir2 and append ls output to file1
   
   
nl:
  number lines in text file. only numbering not empty lines


mkdir:
  creates dir
  mkdir <params> <path>
  -p - creates every unexisting dir along the path, return no errors
   mkdir -p /not_exist1/not_exist2 - will create both not existing dirs 


cp:
  copy stuff
  cp <params> <source1 src2 src3> <destination>
  cp -rf ../source/* .
   -r - recursive copy
   -f - overwrite everything 
   . - current directory with saving all the names and paths from source
  NOTE: to copy hidden files, those star with . , need to escape dot(.) as it is
  regular expression:
  cp /etc/skel/\.* . - will copy all hidden files to current directory
  ............/.* . - will not work
  ............/.*.* . - will copy '..' which is parent directory to current one


rm:
  remove stuff, does not delete dirs and not empty dirs w/o additinal params
  rm <params> <source>
  rm -r <dirname>
   -r - recursive, also deletes directory at the end
   -d - deletes EMPTY directory


du:
  disk usage
  du <params> <file/dir name>
  dy -hs dirname
   -h - human readable
   -s - summary

ln:
  create link
  soft links
  hard links
  ln <param> <path> <link name>
  -s - create soft link


diff:
  checks differences between two files
  i.e.:
  diff packages.list packages.list2
    packages.list:
     pkg1
     pkg2
    packages.list2:
     pkg2
     pkg3
   output:
     < pkg1
     ---
     > pgk3
   read output:
   < - only first file has pkg1, it was on the left in the params list
   > - only second file has it, and it was on the right

bash history:
  ! - invokes the Bash history mechanism
    !echo - will display and execute latest echo from current shell history
	    if such exists, displays error if nothing found(event not found)
   inverts exit code of commands if with space:
    ! true; echo $? # 1 - means exit code 0 was changed to 1
   also inverts pipe exit code
    ls | bogus_command; echo $? # exit code: 127
    ! ls | bogus_command; echo $? # exit code: 0

tar:
  tape archive - collects all files in archive, with savin all permissions
   and user's ownership
  tar <params> <archive> <another_params> <source>
  tar -cvf name.tar directory
   -c - create
   -v - verify\verbose
   -f - files
   -t - view archive , or something like that
   -r - append retular file to the end of an archive i.e:
     tar -rvf uncompressed.tar mybkup/mytest.txt
   -z - zip. tells tar that working with zips and not archives; 
        used for zipping, unzipping, viewing zip,
          if 'czvf' - creates .gz archive, compress same as 'gzip'
          if 'tzvf' - lists zip contents
          if 'zxvf' - extracts zip contents
   -p - preserve permissions
   another params:
    !! could be anywhere in the command, before or after other params
    --exclude=filename - excludes filename/dir/type from adding to archive
      i.e. tar -czvf arch.tar.gz --exclude=file.txt source_dir/
      !! use relative path of tar archive itself! not system file path !!
      !! use path like 'folder/folder/file' w/ or w/o quotas, optional
      !! DO NOT use path like './folder/folder/file' - this will fail silently
  params could be used w/o dash, like 'tar tvf archive.tar'
  Unzip:
    tar zxvf <archive.tar.gz> <path>
   -z - unzips contents
   -x - eXtract it
   -v - verbose
   -f - files
   <path> - cold be empty for current location
  Could pass view output to grep to search for particular file

gzip:
  compress files. it looks for a file it can compress by default even w/o
   specifying its name
  gzip <filename>
  gzil archive.tar
   will substitute 'archive.tar' by 'archive.tar.gz'
  Could be called by 'tar' command using 'z' key, will works the same

mount:
  mount drive (disk, usb, floppy etc)
  mount -o rw,remount /
   -o - dunno.. TODO
   rw - seems to be read\write
   remount - pretty clear at first glance
   / - what to remount

  -a - mount all lines added to /etc/fstab
  
  /etc/fstab - config for filesystems
   read by fsck, mount, unmount
  lines from this file read during 'mount -a'.
   check man fstab for details. 
  simply add automount of HDD from old windows:
  LABEL=Juli      /otherHDD/Juli  ntfs rw,suid,exec,auto,user,async
  labels or UUID could be taken from 'blkid' command


scp:
  secure copy using ssh protocol
   could copy to or copy from remote location.
  copy to remote:
  scp <params> <file_path> <receiving_username>@<address>:<receiving_file_path>
  copy from remote:
  scp <params> <remote_username>@<address(ip\name)>:<remote_local_path> <path>
  params:
  -v - verbose  

sshd(openssh)
  daemon config location:
   /etc/ssh/sshd_config
  sftp enable switch is located there, could be commented out and sshd restart
  to disable it
   /etc/ssh/ssh_config
  some another config
  ==
  RSA keys for ssh authentication generation process:
  https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys-on-centos7
  ssh-keygen [-b 4096] - generates key pair into given path
  ssh-copy-id user@34.250.25.207 - copy pub rsa from local machine to remote
   for the user given further access will be w/o password(could ask passphrese)

ssh-keygen:
  Known hosts are stored in a file /home/<username>/.ssh/knonwn_hosts.
   There are only 1 RSA key is allowed for the IP, in case RSA key is changed, then 
  old one need to be removed, otherwise it will not allow ssh acces:
   ssh-keygen -f "/home/dos/.ssh/known_hosts" -R 172.17.0.2
  
  

sftp:
  secure file transfer protocol, allows to list dir contents
  built-in into OpenSSH server, which workks as sshd service(daemon) together
  with scp
  sftp <remote_username>@<remote_ipaddress_or_name>
 sftp has its own set of directory related commands:
 pwd - print work dir, returns current remote_dir
 lpwd - current local_dir
 cd - change dir, changes remote_dir
 lcd - local change dir, changes local_dir from sftp via OpenSSH daemon
 get - copy file to current local_dir
  get <remote_filename> <new_local_name>
 ls also works, ALIASES from bashrc do not work

===general


===Env Vars / Environment variables:
printenv:
env:
  very similar, prints environment variables to STDOUT
  printenv VAR - prints value of specified variable to STDOUT


set:
  prints ALL variables - Shell vars, local vars, shell functions
  Somewhy it does not have a man page for 'man set'

 Read more of set and printenv\env here:
https://www.digitalocean.com/community/tutorials/how-to-read-and-set-environmental-and-shell-variables-on-a-linux-vps
 Read more of printenv\env history here:
https://unix.stackexchange.com/questions/123473/what-is-the-difference-between-env-and-printenv

How to set\export env variables in bash:
Read export\env differences here:
 http://hackjutsu.com/2016/08/04/Difference%20between%20set,%20export%20and%20env%20in%20bash/

  Set variable ONLY for current shell:
  varname="my value"
  Set variable for current shell and ALL PROCESSES started from current shell:
  export varname="my value"
  For below LogOut is required:
  Set var PERMANENTLY for current user
  ~/.bashrc - add 'export varname="my val"' here
  Set var permanently and SYSTEM WIDE (all users/all processes)
  /etc/environment - add line 'VARNAME="my value"', caps bcs of naming convents
		     'export' is not userd here parser does not know it
  LogOut is required for permanent changes.
  
  Unset:
  unset ENV_VAR
  echo $ENV_VAR - returns nothing , bcs it is unset

  ALSO has options:
  set -o - will display all the options
   one of the options is 'noclobber'
   set -o noclobber - prevents '>' redirection from overriding files
   set +o noclobber - removes noclobber back


execute:
source:
dot (.):
  read more:
  https://superuser.com/questions/176783/what-is-the-difference-between-executing-a-bash-script-vs-sourcing-it/176788#176788

  execute script if it has x permission
  !! CREATES NEW SHELL !!
   ./script - script in current directory(./ dots lash notaion)
   script - execute script if it is in PATH var

  source script even if it does not have x permission
  documentation:
  http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#dot
  !! DOES NOT CREATE A NEW SHELL !!
  Executes commands from a file in the CURRENT environment. 
  In case it is for login-shell, it will update whole command line, probably
   not sure how it will work in case of 'su -'

   source myscript - myscript is param for source so no matter myscript is in
 		     path or not.
		     Still need to be valid shell script(#!/interpreter/pat)  
   . myscript - 'source' is alias for . in bash, syntax from POSIX 

  Source saves stuff changed in script(i.e. Env var updates) to the current 
  shell session where as Execute creates new session where changes are saved
  and kills it after everything is done - basic behaviour of everything





===User\Groups Management

=====User\Groups Management General info
group related info is stored in
  /etc/group   - file, use 'vigr' for edit
user related info stored in 
  /etc/passwd  - file. in case of edit use 'vipw' like 'visudo' with sudoers
default homedir files are stored in
  /etc/skel/   - directory
		 those files will be copied to user home when it is created
  ..../.bashrc - executed by bash for non-login shells - every time bash
		 is started interactively(from command line, which is also bash)
see more: https://unix.stackexchange.com/questions/129143/what-is-the-purpose-of-bashrc-and-how-does-it-work
  ..../.profile - executed by command interpreter for login shells
		  is not read if '.bash_login' or '.bash_profile' exists
  ..../.bash_logout - executed by bash when login shell ended

unlike files in /etc/skel changes to this files will affect even existing users
changes from here will be applied with every re-login to every 
		user on thesystem:
/etc/bash.bashrc -  will affect ~/.bashrc 
/etc/profile -  will affect ~/.profile

/etc/login.defs - useradd/userdel/usermod config
/etc/adduser.conf - adduser config(Ubuntu)
/etc/shadow - secure account info - passwords
/etc/gshadow - secure group account info - passwords

/etc/passwd:
root:x:0:0:root:/root:/bin/bash
root - username
x - placeholder for a password, modern systems use /etc/shadow file for pass
0 - is the user ID(UID) for this user
0 - is the group ID(GID) for this user
root - comment about this user
/root - home directory for this user
/bin/bash - default shell for this user(after he logs in presumably)
	    Possible values:
  /bin/nologin - deny login at all
  /bin/false - deny login but still can be logged in using 'su' command from 
		another account


/etc/group:
wheel:x:10:centos,user
wheel - group name
x - place holder for a password, modern systems use /etc/shadow filr for pass
10 - group id(GID) for the group
centos,user - users in the group, and probably user wheel too
   user along with who group was created id not listed in the group..
   probably to make sure group do or does not contains it , could try check
   groups of that user like 'groups wheel' - it will return 'no such user' if
   there is no user with same name as a group

NOTE: there are Primary group for a user and SUpplementary groups, 
  Primary is the first group of a user, others are suppplementary:
    $ groups johnny
    > johnny : test1 john newgroup1 newgroup2
  to add extra supplementary groups use 'usermod -a -G group1,group2'. 
  To change Primary group use  'usermod -g john johnny'
    > johnny : john newgroup1 newgroup2
  NOTE THAT 'test1' group has been removed at all, and not moved to 
   supplementary groups
  NOTE to change to test1 w/o deleting it user 'newgrp' command:
    $ newgrp newgroup1
    > newgroup1 john newgroup2
  Files created by user are owned by PRIMARY group of the user


=====user\groups management general info end

=====Manipulate Users And Groups
useradd:
  old since any *nix creation. Almost everything need to be done manually bcs of
  compatibility - different *nix platforms handles users differently, their ~
  directories could be different
  useradd -<params> <username>
  -d <~_path> - use if home name\path differs from default location, i.e.:
		 
	useradd -d /home/accounts/john testuser
  useradd -c "John from Accounts" -m -s /bin/bash john
   -c - adds a COMMENT in the /etc/passwd for this acc
   -m - MAKEs the home directory for this user, like /home/john
   -s - assigns the SHELL for the user
   john - actual user name
    user 'john' is the member of group 'john' and this is his PRIMARY group
  also:
   -u <UID> - user ID , first free picked (from range in config) id no specified
   -g <GID\Name> - assign to already existing group. i.e. -g accounts
   -G <GID\Name> - additional group. i.e. -G employees
   -e <YYY-MM-DD> - EXPIRATION date of the account
   -k </path> - sKELETON directory if differs from /etc/skel
   -p <hashed_pwd> - encrypted password for acc, or use 'passwd' command later
   
NOTE: after user is created the password need to be added:
passwd testuser

=====Manual User Creation
user# sudo su -		- become root
root# vipw		- edit /etc/passwd
 add new line with user info like:
 username:x:UID:GID:comment:/home/username:/bin/bash
root# vigr		- edit /etc/group
 add new line with user group info like:
 usergroup:x:GID:
root# cd /home && mkdir username - create user's home folder
root# cp -rf /etc/skel/\.* /home/username/. - copy everything from skel
root# chown -R username:usergroup username/ - change recurse ownership of dir
root# passwd username - create password for the user
=====manual user creation end


groups:
  list groups of a user
  groups [username]
    w/o params gives current user groups
    with username - gives groups of that user

getent:
  getent group <$(whoami)>
  lists all groups on system and users of those groups(similar to /etc/group)

usermod:
  modify existing users
  usermod [<params>] <user>
   -l - change LOGIN of the user. i.e.:
      usermod -l johnny john - change username john to johnny
   -d - DIRECTORY path for New home directory of the user
   -m - MOVE-home dir to new DIRECTORY path
      usermod -m -d /home/johnny johnny - creates new dir for the user and moves
	everything from old dir to new dir
   -g - change primary GROUP
   -G - add to other GROUPs delimited , and no spaces adds, more groups for user
	will overwrite other supplementary groups except primary
   -a - APPEND groups, used with -G, to append existing supplementary groups:
      usermod -a -G newgroup1,newgroup2 johnny - will add two groups to the
	end of the list of a groups user have
   -L - LOCK user
	after lock there will be exclamation mark in /etc/shadow file before
	user passwod:
	johnny:!$6$DQMYnvhr$xKMYZSorH2wePlAunWDBKYWYSK8bmnyKMbr9IAuMoykPl7....
   -U - UNlock user, and remove exclamation mark '!' before user passwd hash
  More to read at:
   https://www.tecmint.com/usermod-command-examples/

userdel:
  deletes user in old way
  userdel <username>
  -r - deletes home directory too

adduser:
  adding user
  shell around perl written useradd command, which is hard to use
   adduser <username>
  CentOS7, does not have adduser, it links it to useradd:
   lrwxrwxrwx. 1 root root 7 гру 14  2016 /usr/sbin/adduser -> useradd

  /etc/adduser.conf - config for this command, has default ids, default shell
			default home dir(/home) and so on
    detailed how adduser works on Ubuntu:
    https://askubuntu.com/questions/659953/what-is-ubuntus-automatic-uid-generation-behavior

groupadd:
  adds group
  info about groups is stored in /etc/group file, see General above for details 
   once group is created use 'usermod' to add users to it
  group [options] <group>
  -g - manually set GROUP id

groupmod:
  modify existing groups
  -g - change GROUP id
    groupmod -g 300 manager - change group 'manager' to have new GID of 300
  -n - change NAME of a group
    groupmod -n managers manager - change group 'manager' to 'managers'

  
passwd: 
  change password for current user
   or for given user
  passwd [username]
  located in /usr/bin/passwd - ubuntu
             /bin/passwd - centos/red hat
  has 'setuid' thing..


gpasswd:
  add\remove users from a group, set admins for the group, set password for
  a group
  gpasswd <params> <group>
  -a <user>  - ADD user to a group
  -M <user1,user2> - add MULTIPLE users, commadelimited w/o spaces
     gpasswd -M john,jane manager
  -d <user> - DELETE user from a group
     sudo gpasswd -d johnny newgroup1 - remove 'johnny' from 'newgroup1'
  -A <user> - add ADMIN user for a group, dunno what it is about.. TODO

newgrp:
  newgrp <groupname>
  Changes primary group of the user w/o deleting any groups
   could freely move between assigned groups 
  And asks for password(probably group password) if trying to set unassigned
  group as primary one

groupdel:
  delete group
  groupdel [params] <groupname>

setuid and setgid:
 setuid:
  Attribute of a file that allows unprivileged user to have level of permission
  of original owner of the file. 
  For example passwd executable is owned by Root user. But unprivileged user 
  could execute it and the passwd binary will made the changes into /etc/passwd 
  and /etc/shadow file(contains some related to passwords stuff too), and those 
  both files also are owned by root user.
  In the same time passwd used by unprivileged user accepts no params - means
  user can not change other users passwords
 setgid:
  Attribute of file\directory inherited byu sub dirs\files, so subdirs inherit 
  parent's attributes. 
  Gives access  equal to group owning the file to unprivileged user executing 
  the file.
  Unprivileged user executes file Under the privileges granted to the user group  owner of that file.

whoami:
 returns username of currently logged user

=====manipulate users and groups

=====Super User
/etc/sudoers - file where all the privileges set. has user accounts with 
		privileges, as well as some groups, 
		for Ubuntu: 
			admin - almost root
			sudo - as root
		for CentOS7: 
			wheel - as root
NOTE: this file must be edited through 'visudo' command, this will ensure safe
  changes including lock file on edit and so on

root access:
  should be disabled for remote login in sshd for security reasons

su:
  su - [<username>] - creates new session for a user, i.e.:
     su - user - log in under 'user' user
  log in as super user(root), need to provide root password i.e.: 
  su -
   - dash is used to call login shell and reset most of env vars, basically safe
     against env related exploits and overriden standard commands. see here:
  https://unix.stackexchange.com/questions/7013/why-do-we-use-su-and-not-just-su
  
  !!!!
  in case root pasword is lost here is how to recover it from recovery mode
  https://askubuntu.com/questions/24006/how-do-i-reset-a-lost-administrative-password
  UBUNTU by default installs with random root password so noone knows it,
   need to use SUDO 
  
  Another way to recover a root password is to add a user to a privileged group
   like 'sudo' or 'wheel' - this way user, using program 'sudo' can become root
   w/o entering the forgotten(random for Ubuntu) password:
  user# groups - make sure user is in sudo group
  user# sudo su -  - become root w/o entering password root's password
  root# passwd  - enter new password

sudo
  TODO
=====super user end


=====user\groups management end

===Processes and Services Management

top: htop:
  gives a list of processes and resources used by the OS
  Process could has a priority:
   20 - is the LOWEST priority
   -20 - is the HIGHEST priority
  PID number 1 is always 'init' command or 'systemd' in my case on ubuntu 16 and
  centos 7

general processes:
  all processes are spawned from process with ID 1, 'init' in manual or systemd
  in my case, for some reason
  so there is a PID which is Process ID
  and PPID which is Parent Process ID, so every process has parent, except PID 1  it seems

ps:
  by default returns processes run by my current user and current terminal 
  session
  ps [-[-]]<params> 
	   UNIX standards - -<params>
	   BSD standards - <params>
	   GNU standards - --<params>
	params could be mixed, but conflicts could appear
   a - list all processes that has terminal attached: ps a
   x - list all processes owned my you(same EUID as ps)
   ax - list all processes(less columns)
   u - user oriented format
   p <pidlist> (-p, --pid)- select process by id (or just PID, == --pid <PID>)
   -C <cmdlist> - select by command name(COMMAND column)
   t <ttylist> - select by tty
   U, -U, -u, --user - selects by user name or EUID(RUID for -U), different 
		selections by user , will output different stuff
   -j - jobs format
   j - job control format
   -H - hierarhy(tree\forest format)
   l - long format
   -l long format , -y good with this
   -f - full format listing
   f - ASCII art process hierarchy (forest)
   o, -o, --format - change columns format
  	i.e. ps -o pid,ruser=RealUser -o comm=Command - wil return 3 columns
		named PID, RealUser and Command, with values of standard colmns

  ps aux - returns all processes run by all users from all terminals
	    if user does not exist 'x' in case of UNIX format it could treat it
	    in BSD format
  ps axjf - formatted method of processes with parents in tree view

pgrep:
  process grep , could find process id (PID) by process name, like
  pgrep bash - will return PID of the bash process running somewhere locally

kill:
  for terminating the processes
  kill <param> <PID>
  each kills param has its number equialent
  -TERM\-15-  sends a Signal to a process (Term[inate] Signal), in other words
   it asks the application to call its Dispose method, to gracefully stop. i.e.
   kill 1292 or kill -15 1292 or kill -TERM 1292
  -KILL\-9 ask OS's Kernel to shut down the process even if the process(app) 
   does not respond for 
  -HUP - restarts process if possible, does not change PID
  -l - lists all the signals available with their names and numbers(minus SIG
   prefix)
  NOTE: only owner of the process(or root) could kill the process

nice: renice:
  changes priority of the process
  nice is for new processes
  
  renice is for already running processes

  renice <priority> <PID> i.e.
  renice 10 1292 - will change priority of process 1292 to 10, and will display
   previous value of the priority 
  
  nice <param> <priority> <binary_path> i.e.:
  nice -n 20 /bin/bash - will start New(-n) process from /bin/bash binary, with
   priority of 20(the lowest one)
   
sysvinit, systemd, upstart
/usr/lib/systemd - systemd service manager working dir (new Rhel\Debian-like)
/usr/share/upstart - upstart service manageer working dir(old Debian\Ubuntu)
/etc/init.d - sysvitin service manager working dir (old Centos\Debian\Ubuntu)
Note: Ubuntu could has all three installed currently, unlike centos that has
initd but it wrapped in systemd


service: daemon:
  RHEL-like - systemd (moved from SysVinit)
	https://fedoraproject.org/wiki/SysVinit_to_Systemd_Cheatsheet
  Debian-like - upstart service (also adopted systemd)
  for Debian-like and RHEL-like systems its two different ways
   for Ubuntu since 15.xx it seems it is even more different..
  Debian-like:
  status <service> 
  start <service>
  stop <service>
  restart <service>
   where service could be like 'ssh' or 'cron'
  to disable\enable services in upstart services the .override file need to be
  created in the /etc/init directory. For instance to disable cron:
   ensure cron exists:
   /etc/init/cron.conf - should exist
   echo "manual" > /etc/init/cron.override - will create text file with word
    'manual' as its only contents
   now cron will not be loaded on boot
   to enable cron back - simply delete 'cron.override' file from /etc/init dir

  RHEL-like:
  systemctl start <systemd>
  systemctl status <systemd>
  -- restart\stop 
   where systemd could be like 'sshd' or 'crond' where d means daemon
  systemctl disable <systemd> - disable system daemon from starting on boot
   basically it will delete soft link from /etc/systemd/... directory which it 
   seems is monitored on Init and everything there is executed
  systemctl enable <systemd> - enable datemon to start on boot
   basically it creates soft link from real binary location of daemon file into
   /etc/systemd/.... directory where all the links for boot are stored

  Ubuntu since 15.xx
  service <service> status
  -- stop\start\restart
   where service could be like 'ssh' or 'cron'
  service --status-all - will return statuses of all the services
!!  TODO: 
   check how to enable/disable services on boot for this new stuff and check how
  it exactly called now
  it seems it also supports systemctl and disable\enable with same commands,
   but creating .override file in the Debian way

===processes and services management

===Package management
=====Debian\Ubuntu

.deb - packages format

dpkg:
  dpackage - debian packages manager, fully console, installs only package
  -i - install a package
     only package , no dependencies - generate error with dependencies required
  -l - list of all installed packages(use grep for specific packages)
  -L <package> - list of all the files that were created during package 
		 installation

aptitude:
  frontend of dpkg, GUI in commandline
   categories of packages, local, available etc, then all the packages by 
  categories. also displays info about each package
  Enter key to open\close category.
  g or u - install selected package

apt-get: apt:
  stands for Advanced Package Tool
   apt is merge of apt-get and apt-cache, for easier use, has not all functions
   but also has some additional functions
  main apt tool used to install or download packages
  reads dependencies, and could install all of them
  apt-get update - reads all the repos and updates the local packages cache
  apt-get install - installs package(s), list delimited by space
       or install <package-2.3.5-3ubuntu1> - installs particular version if
		    it is compatible with distro and stuff   
  apt-get upgrade - made after Update, upgrades all the packages installed to
		    latest updates
          -y - answer Yes for all questons automatically
  .. dist-upgrade - updates to next available supported distro, 14.04 to 14.10 
		    if 14.10 is not supported already then to 15.04 etc
  apt-get autoclean - cleans cache, which means freeing space on hdd

  apt search <pkg> - search for package
  apt list --<params> - lists available packages from repos
	   --installed - lists only installed packages
  apt show <package> - shows info about package(apt-cache's command)

  --dry-run - simulation, will display possible actions but not perform any

  apt-get check - what dependencies may be broken
  apt-get build-dep - exact build dependencies for particular app (it seems it 
		is not necessery to download them all for work though...)

  apt-get download <package> - downloads package(probably to current dir
			       or /etc/apt?) - but only package w/o dependencies
  apt-get changelog - package changelog, like version history

  /etc/apt/ - apt configs
   sources.list - config of the repositories, which are re-read during 'update'
   		  command execution
  /var/cache/apt - cache folder of apt
  ./archives - contain all the archives, could be removed by 'autoclean' command

apt-cache:
  support tool of apt used to work with apt cache(updated by apt-get cache 
  command)
  apt-cache pkgnames - list of all pkgs APT knows, not all could be downloaded
			installed or installable e.g. virtual pkgs
  ... search <package> - lists all packages that contain package name in its 
			 name or description
  ... show <package> - info about the package, like description in apptitude
  ... stats - info about local cache(packages related stuff) - could be shrinked
  	      by running 'apt-get autoclean' to delete useless stuff

apt-file:
  another extension for apt-get, is in different package, 
   need to be installed first

  apt-file update - updates its own caches, need to be run first
  apt-file find <pattern>  - alias for search, see below:
  apt-file search <pattern> - search packages for file matched by pattern.
		returns list of packages and paths where file was found;
		includes removed packages too
  apt-file list - similar to dpkg -L but package not need to be installed or
		fetched

=======Uninstallation
  apt-get remove <package> - removes package binaries, leaves configs in the 
		             system for future use by other version or another
			     reason
  .. remove --purge <package> - removes package and all the stuff package 
  .. purge <package> ^same^     created during install(SYSTEMWIDE configs, link
				etc)
		it will not remove:
		 -dependence packages , to delete orphanes use
			apt-get autoremove
			  or
			.. --purge autoremove (same - will remove configs also)
		 -NOT SYSTEMWIDE config files - user-specific files
			files in user's home dir, or .config subdirectory of 
			home, those could be hidde (starts with .)
  		 -doesn't reverse changes in already existing user-specific
		  config files
		 -doesn't remove 'gconf' and 'dconf' files or reverse any
		  configuration d\gconf changes
	existing SYSTEMWIDE configs also are not affected by neither purge or
	remove commands, those ones created by user or other packages. but 
	uninstalling package could sometimes affect such files and undone 
	something
  apt-get autoremove - removes all orphaned packages
  .. purge --auto-remove <package> is similar to autoremove
=======uninstallation end

=======Repository setup
  Due to regular use of secure stuff also make sure following packages are
  installed(use apt-cahce show <package name> or 'apt list --installed'):
   apt-transport-https - This package enables the usage of 
	'deb https://foo distro main' lines
	in the /etc/apt/sources.list so that all package managers using the
	libapt-pkg library can access metadata and packages available in sources
	accessible over https (Hypertext Transfer Protocol Secure).
	  This transport supports server as well as client authentication
	 with certificates.
   ca-certificates - list of PEM files of certificates approved by Certificate
	Authorities, some common trusted certificates. For instance it has
	certificates for Debian stuff and Mozilla stuff.. 
	TLDR:
	It is a list of default trusted SSL sertificates stored in PEM format.
   curl - tool for transfering data from or to a server via HTTP/S, FTP/S, LDAP
	and lots of other formats, except SSH, but it has SCP..
	Used to download GPG key from docker storage. Which is added then to
	local apt storage
   software-properties-common - adds additional command for APT repositories 
	management. Such as 'add-apt-repository'

  Add gpg key:
	curl -fsSl https://download.docker.com/linux/ubuntu/gpg | sudo apt-key
	add -
	  Curl will download gpg key from docker , then pass it to apt-key (-) 
	and it will be added to local key storage
    make sure it is added, by searching for fingerpring:
	sudo apt-key fingerprint 0EBFCD88 - this will return OK if everything is
	fine
  Add a STABLE repository, it seems it is required:
	it is stored in:
	/etc/apt/sources.list - the file with the sources, where 
	add-apt-repository will add the repo by default
	/etc/apt/sources.list.d - directory where new file with a repo should be
	added, like in CentOS' yum
	add-apt-repository example:
	sudo add-apt-repository \
	   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
	   $(lsb_release -cs) \ - returns distro name
	   stable" - list of repos, test, edge could be added for docker
	
   

=======List all installed packages:
  dpkg -l - list of packages and their details
  apt list --installed - list of full names
  aptitude - has a category for installed pkgs divided by categories

=====debian\ubuntu end

=====RedHat RHEL\Centos

  .rpm files
rpm:
  red hat package manager
  It seems it has some differend modes, where similar keys could exist with 
  different functions, i.e. -i - installation mode, -i in -q(query) mode is info
   the modes are:
   - install/update/freshen (first param -i)
   - uninstall (first param -e)
   - query (first param -q)
   - verify (first param -V probably)
   - set owners/groups
   - show querytags
   - show configurations
  Also it has general options, seems like it works with any mode
  if files or dependencies package need are absent installation of rpm will fail
  -q - query, probably 'what about something, like package requirements'
	single param will display package full name if it is installed or will
	say that it is not installed, i.e.:
!	rpm -q openssh-server - will return fill name if installed, like this
				openssh-server-7.4p1-13.el7_4.x86_64
   -p - package file
   -R - requires, lists package dependencies
  i.e.:
  rpm -qpR <rpm_package or package_name> - will list package requirements(depen
	dencies), if rpm_package name is given(xterm-123.3.rpm) - will check for
	package locally	if general package name is given(xterm) will look into
	remote repos
   -l - list files of the package, similar to 'dpkg -L' i.e.:
	rpm -ql openssh-server - will list all the files and paths of sshd
   -a --last - will list (a)ll the packages installed filtered by latest
   rpm -qa | grep nmap - will list all Installed packages, and grep nmap from 
		this list
   -d - documentation mentionings of a package 
   -f - some related to documentation param
   rpm -qdf <package> - return all documentation files where this package is
		mentioned
  -i - installation mode (fails if package installed of any version)
   -v - verbose (general parameter)
   -h - prints some hashes, looks better with -v
   -U - update package, BUT will install package if there is none installed
	if package is installed will not fail but update it(controversy to -i)
  rpm -Uvh <rpm_package or package_name> - will update or install package, 
	fails if there are missing dependencies
  -e or --erase - erase package, uninstall mode
   -v - short verbose mode, RETURNS NOTHING if no Verbose mode is passed
   -vv - very verbose, dunno why not -v
  -V - verify, there is some verification key for every package and rpm could
	check whether the package indeed has that key
   -a - all, same as for -a in Query mode of rpm tool 
   Keys could be imported from remote repos, or rpm could list all the keys
   that has been already imported
   rpm --import - will import key somehow from somewhere..
   rpm -qa gpg-pubkey* - will list all the public verification keys on system
  
yum:
  Stands for "Yellowdog Updater, Modified". yellowdog is already unsupported 
  version of Linux for PowerPC, which is also dead now
  yum <params> <package_name>
  Package management system
  yum update 
  yum upgrade - same as update - updates all the pkg repos and upgrades pkgs

  yum list [<pkg>] - displays if installed, version, and @updates mean that it
		   accepts updates. Package could be market to ignore updates
		   which probably means that yum update will not affect it
  ..  list installed - returns list of installed packages
  yum search <pkg> - searches for package, search in name and description
  yum install <pkg> - install package, and its dependencies
	-y - answer Yes for prompts automatically
  yum localinstall <pkg> - installs .rpm package downloaded to local machine
	will ALSO install needed dependencies, unlike 'rpm' tool
  yum info <pkg> - info about a package: descr, url, size, arch, etc
  yum check-update - checks which packages could be updated
     -C - use only local cache, doesn't update cache
  yum grouplist - YUM can group packages, this command displays all the groups
		  those groups will install bunch of packages
  .. groupinstall '<group name>' - will install all the packages from the group
  .. gropuremove '<gn>' - removes all the packages related to the group
  .. groupupdate '<gn>' - updates same stuff

  yum repolist - lists all available(enabled) repositories
  ..  .. all - lists all the repos disregard of their staus
  .. --enablerepo=<repoid from repolist> install <pkg> - enable a repo and
		install the package from that repo
  yum provides <feature or file> - Just use a specific name or a 
  	file-glob-syntax wild‐cards to list the packages available or installed
	that provide that feature or file.
  yum clean all - clears cache similar to apt-get autoclean
  yum history - history of yum - install\remove\upd package and stuff, sudo

=======Manage repositories
repos stored in /etc/yum.repos.d, which is a directory
to add new repository:
 create new file in the /etc/yum.repos.d dir named '<anything>.repo'

Format of repo file:
[dockerrepo]  - name of the repository section
name=Docker Repository - name of repo to display
baseurl=https://...    - address to where from do pulls of packages
enabled=1	       - repo is enabled inside my system
gpgcheck=1	       - enables gpg check
gpgkey=https://....    - location of the key


=======Uninstallation
  yum remove <pkg> - removes the package, doesn't remove its dependencies
!   yum autoremove <pkg> - also removes package, probably its deps too..
  To remove dependencies there are several ways:
  Option1: [probably should do this as standard]
  yum autoremove - removes orphaned dependencies, similar to 'apt-get utoremove'
  Option2: [probably could try this]
  update /etc/yum.conf file
   set
    clean_requirements_on_remove=1
   it is boolean value, which works on removel\update\obsoletion, goes through 
   each package's dependencies and deletes ones that are no longer required.
   default value False, could be 1,0,True,False,yes,no
  Option3: [probably better try not to use it]
  yum history undo <ID>
  basically in undoes the operation, that was performed during installation
  and thus removing the package and all the dependencies, and probably other
  stuff. 
  the only thing here is that i'm not sure whether it checks that package from 
  dependencies is dependent only by this package that caused them to be 
  installed, or not, so is not - it could end up with broken dependencies
  so how to do:
  yum history - check the ID column next to the command line with installation
  command of the package that need to be uninstalled
  then call 'yum history undo <ID>'
=======uninstallation end

=======List all installed packages:
  rpm -qa - query all packages, will return list of all installed packages
  yum list installed - will return list of installed packages


yum-utils:
  yumdownloader:
  yumdownloader <pkg>
    downloads a .rpm file, into current dir pretty similar to apt-get download
    command
=====redhat rhel\centos end
===package management end

===File Permissions / Ownership

! Linux treats everything - device\file\directory as if it is a FILE

drwxrwxrwx:
d - type of file(file\device\dir\link)
 r - read
   r only gives ability to list contents, but lots of ????? and file names
    can't even read files with 'cat' and stuff, need x permission for this
 w - write
 x - execute
   x only gives ability to 'cat' files, but cant ls into dir
    if file in such dir has only 'r' can even 'cat' it, if file has only x: cant
     cat it, need 'r' on file in dir with only 'x' to cat
   together with read - can ls norm and execute stuff like 'cat' to read file
first 3 - user permissions 
second 3 - user's group permissions
third 3 - all other users

chown:
  changes owner and group of a file\directory\link
  chown <params> [user][:group] <file/dir>
		 -reference=R_FILE FILE
  !!!! links could change owner of targeting file only!!!!!!!!!!
  -h \ -H - for changing owner of LINK not referenced location, see MANUAL
  -R - recursively change owners of nested directories
  -v - verbose, could be redirected to a file for future use, just in case
   in case of fucked up links
  could change only owner(<owner>), only group(<:group>), or both(<owner:group>)  could take ownership schema like owner:group from a file:
   chown --from=:user :otheruser file.txt

chmod:
  change modification
  chmod [<params>] <permissions> <file_path>
  text modifications:
  u - owner
  g - group
  a - all
  r/w/x - read/write/execute
  i.e.
  chmod a+rwx <filename> - give all the permissions of read/write/execute

  binary mode:
  4 - read
  2 - write
  1 - execute

  sum of numbers above will indicate permissions
  rwx = 4+2+1 = 7, and so on 

  Parameters:
  -v - verbose for every file processed
  -c - changes (less verbose), only when change is made
  -f - supress most error messages, --silent, --quiet
  --preserve-root - fail to operate recursively on '/'
  -R - recursive

lsattr:
  lists extra attributes of files on linux file system
  lsattr file1 - display attributes of the file1

chattr:
  changes extra attributes, lots of them, here some:
  i - immutable (can not be changed)
  a - appendable (can be opened only in append mode)
  u - undeletable
  syntax: 
  + - adds attribute
  - - removes attribute
  = - causes  selected attrs to be only attrs that files have..(not sure)
  i.e. 
  chattr +u file1 - adds undeletable attr to file1

===file permissions / ownership end

===IPTables / Linux kernel Firewall(not d)
read more:
https://www.unixmen.com/iptables-vs-firewalld/
https://linuxacademy.com/cp/socialize/index/type/community_post/id/15473

!!!!!!!!!!!!!!!!
!!  WHen using SSH configure SSH rules first BEFORE changing 
!!    the policies of the chains in the Filter table. 
!!  !!    TO DO NOT LOCK MYSELF OUT OF THE MACHINE  !!  !!   !!   !!
!!  CentOS 7 applies the rules right after entering the command
!!  even if Service IS stopped.
!!!!!!!!!!!!!!!

///Iptables is a tool to work with Netilter Framework, kind of firewall
/There are different services on different Linux distributions such as:
Ubuntu - ufw(Uncomplicated Firewall) service for Ubuntu, which uses IPtables
Centos7 - firewalld - firewall daemon which uses iptables
generic? - iptables-services - firewall service that uses iptables, generic 
	   it seems


Main three groups or something:
Tables:
 used to group different functionalities and separated in five:
 - filter - default table if no specified. Packet filtering.
   Built-in chains:
    - INPUT
    - OUTPUT
    - FORWARD
 - nat - used for network address translation(NAT)
 - raw - first table to check, configuring exemptions from conn. tracking
 - mangle - some specialized packet alteration...
 - security - Mandatory Access Control(MAC) networking rules
 -t\--table - parameter to specify a table

Chains:
 Tables contain set of chains.
 Chains group rules on different points of process.
 Chains could be Built-in or User defined.
  INPUT - Filter. input packets
  OUTPUT - Filter output packets
  FORWARD - Filter. going through packets
 -N\--new-chain - adds user defined chain
 -X (--delete-chain) - delete chain

Rules:
 Defined as a set of matches and a target. 
 Are listed in chains and followed by order until a match is found, then packet
 is handled by the target specified by the rule.
 -A (--append) - add new rule
 -D (--delete) - delete rule along with the chain in which is contained
 -L (--list) - list rules
 -S (--list-rules) - same list but in command format, as if the commands
		     that were used to add rule is saved and displayed here


 Matches:
   if match is true the packet will be processed by iptables.
   Following matches exist(not full list):
   -s (--source) - source of the packe(IP, hostname or network IP)
   -d (--destination) - destination of the packet(IP, hostname or network IP)
   -p (--protocol) - protocol(tcp/udp/all , all - default if none specified)
   -i (--in-interface) - interface that receives(left side of ifconfig output)
   -o (--out-interface) - output interface
   ! - Not. Match everything that is not in the match.

  Protocols has also its own matches, like 
   --dport - destination port(22 for ssh) is match for TCP protocol
  see full list of protocol related matches:
   iptables -p <protocol> -h - where protocol is tcp, icmp etc i.e.:
    iptables -A INPUT -p tcp -i eth0 --dport 22:25 -j ACCEPT 
      - adds rule to default table (-t filter) , appends Chain INPUT, matches:
	protocol TCP and interface eth0, protocol specific match port with
	range of ports 22 to 25. Rule's target if match is met - ACCEPT. 
	If not next rule will be processed until RETURN or end of rules, then
	Default TARGET(Default policy) will be applied.

 Targets:
  Determines the action to be taken if packet is Matched.
  -j (--jump) - specify Target
  There are 4 built-in Targets:
   ACCEPT - no checks , just accept packet
   DROP - refuse packet, do not send a response(simply ignore it)
   QUEUE - sends the packet to user space
   RETURN - returns to previous chain, or handle by Chain policy(Default?)

Default Policies:
  When packet is not matched by any Rule on the Chain - it is handled by the
  target specified in the policy of that chain.
  Two main approaches:
   Accept everything by default, and add rules to refuse access
   Refuse everything by default, and add rules for accept
  -P (--policy) <chain> <target> - set default policy for a chain with target


iptables:
  a generic table structure for the definition of rulsets
  basically ruleset of Linux kernel firewall
  it is a tool to get daemon(service) install other app:
   Centos - iptables-services
   Ubuntu\Debian - ufw(probably goes with iptables pkg)
   RHEL - iptables
   
  
  -L - list all rules currently installed on the system
  -A <section> - ADD

Service uses loads default config file when starts, applying some 
default rules, /etc/sysconfig/iptables for CentOS 7
  to manage a service:
   Debian/RHEL: sudo /etc/init.d/iptables start\stop\status
   Ubuntu: sudo service ufw start\stop\status
   Centos: servicectl start\stop\status iptables

IP address ranges:
CIDR blocks
https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation
https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#IPv4_CIDR_blocks

===ip tables / firewall

===Bash
=====Bash command line shortcuts
ctrl + a - moves cursor on the beginning of the line
ctrl + e - moved cursor on the End of the line
ctrl + u - removes everything from cursor position to the beginning of line
ctrl + k - removes everything from cursor position to the edn of the line
ctrl + w - removes previous word(space separated)
ctrl + l - cleares screen except of current command LINE
ctrl + p - last executed command shown in command line, same as UP ARROW key 
ctrl + c - terminate current process + exit\del current line by terminating it

=====Bash Shell
alias:
 new aliasws workws only for current session
 alias <new name>="<command>" - adds command as alias
 alias <old name> - shows command

sleep:
  just regular sleep, stops current thread for amount of given seconds

bash:
  man bash
  
  -c - accepts a whole bunch of commands like:
  /bin/bash -c "while true; do echo HELLO; sleep 1; done" - which will execute
	echo HELLO endlessly witn interval of 1 second.
	This even could be passed into a container:
   docker run -d ubuntu:xenial /bin/bash -c "...."


  could customize command prompt from default <user>@<hostname>:<path>$ 
  to something like <HH:MM:SS> <user> <whatever>!
   \t - 24 hour time format
   \w - full current path
   \w - current directory only
   \u - username
   \j - amount of running jobs
   \h - hostname

history:
  lists history, dumps .bash_history file into STDOUT, lines numbered
  -c - Clear history, but only in session, .bash_history remains the same
	only in CentOS it seems, ubuntu does nothing

which:
  shows location of a command and its alias if exists
  can search by alias too
  which <command\alias>
   i.e.
  which ll - will return alias line and path for binary

whereis:
  searches for binary file, sources, man files of the command
  Does not work with aliases!
   i.e.
  whereis pwd - will return path for binary and path for man page
   -b - search only for binaries

Streams and Redirects:
 Linux\Unix philosophy is that 'everything is a file' but in fact this are not
  files but block defices stored in /dev or /proc directories, and not files but
  some stuff stored in RAM for instance
STD - means standard
  Read More:
  https://stackoverflow.com/questions/3385201/confused-about-stdin-stdout-and-stderr
STDIN:
  I/O Stream
  file handle that process read to get info from user
  NOTE:
/dev/stdin is a symlink to /proc/self/fd/0 -- the first file descriptor that the
  currently running program has open. So, what is pointed to by /dev/stdin will
  change from program to program, because /proc/self/ always points to the 
  'currently running program'. (Whichever program is doing the open call.) 
  /dev/stdin and friends were put there to make setuid shell scripts safer, and
  let you pass the filename /dev/stdin to programs that only work with files, 
  but you want to control more interactively. (Someday this will be a useful 
  trick for you to know. :) 
STDOUT:
  I/O Stream
  process writes normal info to this file handle
STDERR:
  I/O Stream
  process writes error info to this file handle

  > - used to redirect STDOUT in cli to someplace else (i.e. file instaed of 
	console)
  2> - redirects STDERR
  >> - redirects STDOUT\ERR but file will not be overwritten, and appended 
	instead
  < - redurects STDIN, it will take data not from command line but from
	something else, i.e. a file
  cat /etc/passwd > /tmp/out     # redirect cat's standard out to /tmp/out
  cat /nonexistant 2> /tmp/err   # redirect cat's standard error to /tmp/error
  cat < /etc/passwd              # redirect cat's standard input to /etc/passwd
    or like this:
  cat < /etc/passwd > /tmp/out 2> /tmp/err

NOTE: redirect Standard Output(and error too) to null will hide it from everyone
  like this:
   ls secret_place >> /dev/null - will drop output into a void!!11
  Errors also could be hidden like this, in case of exposing of some secure or
  sensitive info

Redirect SDOUT and STDERR into two files in the same time:
  cat goodFile notExistingFile >mystdout 2> mystderr
	mystdout will contain standard output
	mystderr will contain standard error output

Redirect STDOUT and STDERR into single file:
  cat goodFile notExistingFile >mystdout 2>&1
	mystdout will contain both STDOUT and STDERR

noclobber:
  is an option set-up by 'set' command
   prevents redirection '>' from overriding files. it will return an error
  


pipe: |:
  redirects standard output of first program into standard input of another
  
cut:
  Removes section from each line from a File
   Or parses each line in file by delimiter(Default is TAB) and could retreive
   only selected columns, or bytes - this is for -f option
  cut <param> <filename>
  See more: https://www.computerhope.com/unix/ucut.htm
   Example:
  cut -f1 -d: passwd - will get only first field(-f1) from a file passwd
		fields are created by delimiting by colon(-d:)
  -b --bytes=LIST - cuts out bytes
  -c --characters=LIST - cuts out characters(in different encodings 1 character
	could be more than 1 byte, which is 8 bits)
  -f --fields=LIST - uses delimiter(default TAB) to parse each line by it then
	it could return columns mentioned in the list by numbers from 1
  How LIST works:
   !List of Integers
   !Starts from 1
   list of Integers, or range of integers, or multiple ranges, Separated by 
   commas. Selected columns is printed in the same order they were read,
   written to output exactly once(dunno what it means)
  N - the Nth byte, character or field
  N- - range from Nth byte,char,field to end of the line
  N-M - range from N to M as above
  -M - from beginning of the line till M
  -f Option:
  cut -f 1-2,4-5 data.txt - will cut 1st,2nd, 4th, 5th columns from data.txt
   --output-delimiter - changes delimiter in the output i.e.:
    cut -f 1,3 -d ':' --output-delimiter=' ' /etc/passwd - will substitute
	colon delimiter ':' to space ' ' in the OUTPUT of command for easier
	read
    ..... --output-delimiter=$'\t' - will substitute colon ':' for tab '\t'
	character, '$' here is for escapt
  -c Option:
   cut -c 3-12 data.txt - will cut from 3rd to 12th characters in the data.txt
		will not use delimiters at all
  -b Option:
   cut -b 3-12 data.txt - will cut rom 3rd to 12th BYTE, in case of ASCII 
		encoding it will be the same with -c as there 1 char == 1 byte

  Advanced example:
   grep '/bin/bash' /etc/passwd | cut -d ':' -f 1,6 - greps passwd file for 
	users that use /bin/bash as their default shell, and prints out 
	username and user home directory
	So cut accepts STDIN redirection

bash escapes:
special symbols:
$'\t' - print tab, which is not printable character, same as /r/n or somehting

=====Bash Scripting
test:
 [ 1 -eq 1 ]    - ints compared with -eq, -lt, -gt, -ge, etc
 [ 'a' = 'a' ]  - strings compared with =, <, >, >=, etc
  tests condition, returns 0 if test is passed(true)

  -f <file> - file exists, aviode ~
  -d <file> - directory exists
  -h <file> or -L - symlinc exists
  -s <file> - exists and has size greater than 0
  -u <file> - exists and set-user-ID bit is set
  -k <file> - exists and its sticky bit set 
  -r <file> - file exists and with read permission
  -w <file> - file exists and with write permission 
  -x <file> - file exists and with execute permission
  -z <string> - length of string is 0

  Test could be performed from script , better to use braces [ . ]
  Also could be preformed right inside CLI, it will return nothing, so need to
  create manual then\else-like structures:
   test -f '/path/to/file name' && echo "exitcode: &?. True" || echo "exitcode:
 &?. False" - test for file existance, then if exit code 0 will execute second 
	echo with True, else (OR) will execute echo with False.
      &? -  will print exit code of previously executed command, which in this 
	case is 'test' command

  Test even can be performed w/o test itself:
    Example:
  curl -s google.com | egrep -ci '301 moved' > /dev/null && echo "file has moved
" || echo "false" - curl will pass STDOUT to egrep which will try to match 
	string '301 moved', if it succeed exit code will be 0.
	And first Echo (after &&) will be executed
	Else, egrep will return 1, and thus second echo (after ||) will be
	executed
  
for:
  regular for loop could be done in command line too

  for i in `command`; do echo $i; done
    backtick -  `, does the job, expression between it will be executed in 
	sub shell and its result will be returned, when we have a collection
	we could iterate it with FOR 
  for line in `cat file1`; do echo $line; done
	

===Other programs:

elinks:
  command line browser, with interface similar to MC or aptitude
  
mc:
  two-windowed GUI to work with file system


===Nginx
  fast web server, could be used as load balancer between servers(docker 
   containers) - reverse proxy server

  package name: nginx
  /etc/nginx - config(as usual in etc dir)
    ...conf.d - directory for some main configs probably
    ...default.d - directory for default configs
    ...sites-available - directory for available sites, convention directory
	does not exist by default
    ...sites-enabled - same as previous
	Read more about sites-* here:
	https://serverfault.com/questions/527630/what-is-the-different-usages-for-sites-available-vs-the-conf-d-directory-for-ngi

    Basically all the configs are included in main config:
    /etc/nginx/nginx.conf
	it includes all the configs from directories mentioned above
	same settings from different configs are overwritten by later added:
	first.conf(a=1, b=2), second.conf(b=4, c=3) will be treated like this:
	a=1, b=4, c =3
 !!! MAKE SURE to follow syntax !!!
	'upstream' directive can not be added before http{} section 
	or inside http{} section

	So all includes need to be made correctly
	also not all directives could be added into configs that are included
	because it could lead to conflicts and Nginx wont start
	
	IF nginx is not starting check:
	journalctl -xe - for service errors

	IF nginx throws errors or behave in not expected way check error log
	its location in nginx.conf file
	default location: /var/log/nginx/error.log

    Nginx could refuse connection:
	(13: Permission denied)
       this related to SELinux, which also has error log:
	sudo cat /var/log/audit/audit.log | grep nginx | grep denied
     SELinux has bool values that Nginx and Apache and probably others use
       getsebool -a | grep httpd - will return all bools related to httpd 
	and Nginx(it uses them too)
     To allow connections set:
	setsebool httpd_can_network_connect on - or use 1
	-P - will set it permanently
	

    Config setup, for proxy server:
    Option 1:
	create config with following stuff:

#pool for balancing? should be after http{} section
upstream containerapp {
        server localhost:8081; #- not sure whether localhost is fine
        server localhost:8082;
}

#server configuration
server {
        listen *:80; #everything coming to port 80

        server_name localhost;
        index index.html index.htm index.php #match any such file and use it

        access_log /var/log/nginx/localweb.log; #save logs here
        error_log /var/log/nginx/localerr.log;

	#location is root , for some reason
        location / {
		#pass traffic coming through port 80 into the pool
                proxy_pass http://containerapp; 
        }
}

     Option 2:
	Add upstream (with local network IPs) into nginx.config after http{}
	section
	Update server{} like above, but w/o *_log fields
	Server_name also use local network IP
	ALso i commented default 'root' not sure if this necessary




